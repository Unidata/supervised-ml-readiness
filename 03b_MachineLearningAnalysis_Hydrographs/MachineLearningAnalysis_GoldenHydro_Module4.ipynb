{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9805bfd2-b31d-4b2f-b325-a409c27f96c7",
   "metadata": {},
   "source": [
    "<img src=\"https://elearning.unidata.ucar.edu/dataeLearning/Cybertraining/analysis/media/NSF-Unidata_lockup_vertical_2023.png\" width=\"150px\" align=\"right\">\n",
    "\n",
    "# Machine Learning Analysis in the Earth Systems Sciences\n",
    "\n",
    "In this module, you are tasked with planning, implementing, and evaluating a machine learning solution for a real-world scenario. Given pre-configured code blocks and prepared data, you will create a problem statement, explore the data, experiment with model development, and ultimately make a recommendation on the utility of machine learning for your scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e3747f-a6cf-4326-9e5c-67117de117b9",
   "metadata": {},
   "source": [
    "# Title\n",
    "\n",
    "Intro<br><i>Video opens in a new tab.</i>\n",
    "\n",
    "<a href=\" \" target=\"blank\"><img src=\" .png\" width=\"600 px\">\n",
    "</a>\n",
    "\n",
    "<a href=\" \" target=\"blank\">Transcript</a>\n",
    "\n",
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "<p class=\"admonition-title\" style=\"font-weight:bold\">What is a data engineer?</p>\n",
    "    <p>Your team includes yourself, your team lead, and a data engineer. Data engineering is an emerging career that encompasses the collection, storage, and pre-processing of data in data science disciplines. You will see the type of work that the data engineer on your team does in <i>Part 2: Data Handling.</i></p>\n",
    "    <p><a href=\"https://www.mongodb.com/resources/basics/data-engineering#what-is-data-engineering\" target=\"blank\">Learn more</a></p>\n",
    "</div>\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5cad94-efb5-4291-830e-64a8ad7ea483",
   "metadata": {},
   "source": [
    "Now you will begin the process of following the supervised machine learning model framework to address this task, starting with <b>problem framing</b>.\n",
    "<center><a href=\"https://elearning.unidata.ucar.edu/dataeLearning/Cybertraining/analysis/media/RevisedFull_NOPROCESS_.png\" target=\"blank\"><img src=\"https://elearning.unidata.ucar.edu/dataeLearning/Cybertraining/analysis/media/RevisedFull_NOPROCESS_.png\"></a><br><i>Click to enlarge</i></center>\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8ffff5-7731-4142-bd98-d9f5db95dd13",
   "metadata": {},
   "source": [
    "## Part 1: Problem Framing\n",
    "\n",
    "Based on the information provided in the video, which type of machine learning analysis is most appropriate for this scenario? \n",
    "\n",
    "> **Instructions**\n",
    "> \n",
    "> Execute the two cells below. After executing `display_knowledgecheck()`, select the corresponding button to check your understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bee4cd7-65d4-47b5-b461-48d17890a0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First import the Python tools needed to display the buttons\n",
    "# This cell may take a moment to complete\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output, HTML, IFrame\n",
    "\n",
    "from analysis_tech import display_knowledgecheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8d6ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e093465f1304fe285972a72484408a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='Which type of machine learning analysis is most appropriate for this scenario?')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53689c839a8c43b0b51aa97f607d0c6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='Classification', layout=Layout(height='200px', margin='10px', width='200px'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a81609778184a22835916cf4cf6d18a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_knowledgecheck()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c41fcf-e3c0-488e-9c71-de6c5d088b12",
   "metadata": {},
   "source": [
    "#### Problem framing questions\n",
    "As a part of the problem framing step, we must answer a series of questions to ensure we're creating the best solution for this scenario. \n",
    "\n",
    "***Does a simpler solution exist?***\n",
    "\n",
    "&emsp;<>\n",
    "\n",
    "***Can machine learning requirements be met?***\n",
    "\n",
    "&emsp;<>\n",
    "\n",
    "***Which scientific question should be answered?***\n",
    "\n",
    "&emsp;You will answer this question in **Exercise 1** below. \n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd95337-12f5-4e9b-a786-979ebad08b20",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "<p class=\"admonition-title\" style=\"font-weight:bold\">Exercise 1</p>\n",
    "    <p>Open your <b>Machine Learning Model Handbook</b> to Exercise 1. Then type the scientific question to be answered for this situation.</p>\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "*** \n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40af46bf-61eb-4cdd-8701-aa774ffce5af",
   "metadata": {},
   "source": [
    "## Part 2: Data Handling\n",
    "\n",
    "<center><a href=\"https://elearning.unidata.ucar.edu/dataeLearning/Cybertraining/analysis/media/RevisedFull_NOPROCESS_.png\" target=\"blank\"><img src=\"https://elearning.unidata.ucar.edu/dataeLearning/Cybertraining/analysis/media/RevisedFull_NOPROCESS_.png\"></a><br><i>Click to enlarge</i></center>\n",
    "<br><br>\n",
    "\n",
    "Recall that data handling is often the most time-consuming step of developing a machine learning model. Data handling comes in three parts:\n",
    "1. Locate data of interest\n",
    "2. Explore data\n",
    "3. Create a data splitting strategy\n",
    "\n",
    "Your team's data engineer has located the data and completed the pre-processing for you already. You will continue with your own independent exploration of the data and then create a data splitting strategy. \n",
    "\n",
    "<br>\n",
    "\n",
    "### Part 2a: Locate Data of Interest\n",
    "\n",
    "Intro <br><br>\n",
    "\n",
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "### Metadata Document for X\n",
    "\n",
    "#### General Information\n",
    "\n",
    "Dataset Name: \n",
    "\n",
    "Description: \n",
    "\n",
    "Date Range: \n",
    "\n",
    "Geographic Coverage:  \n",
    "\n",
    "Data Frequency: \n",
    "\n",
    "Last Updated: \n",
    "\n",
    "#### Data Structure\n",
    "\n",
    "File Format: .parquet\n",
    "\n",
    "Number of Records: \n",
    "\n",
    "Columns (Features) \n",
    "\n",
    "- \n",
    "\n",
    "Stations:\n",
    "\n",
    "- \n",
    "\n",
    "<a href=\" \" target=\"blank\">More station info</a>\n",
    "\n",
    "#### Data Quality\n",
    "\n",
    "Missing Data: \n",
    "\n",
    "Outlier Handling:  \n",
    "\n",
    "#### Data Provenance\n",
    "\n",
    "Source: (<a href=\" \" target=\"blank\">Citation</a>)\n",
    "\n",
    "</div>\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ce9319-3e5c-4632-a488-b777f93c9603",
   "metadata": {},
   "source": [
    "### Part 2b: Explore Data\n",
    "\n",
    "While your data engineer colleague prepared the data for your model and created the metadata document, you will still need to familiarize yourself with the data before you use it as input to a machine learning algorithm. In this step, you will take a closer look at the potential features for your model with a few plots. \n",
    "\n",
    "First, let's read the data into this workspace. The data resides on a remote THREDDS Data Server, which serves data to users without the need to manually download files to a local computer. When you execute the code cell below, you will load the Python library `pandas` that includes all the tools for reading the data from the THREDDS Data Server and opening it in this workspace. \n",
    "\n",
    "> **Instructions**\n",
    "> \n",
    "> Execute the  cell below.\n",
    "> \n",
    "> *This may take a moment to complete.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6d6c37c-c245-4006-9e15-2c3674b17da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pandas and numpy Python library that can interpret the data file\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Location of the data on the THREDDS data server\n",
    "file_path = 'clear_creek_hydro.parquet'\n",
    "\n",
    "# Read data into this workspace\n",
    "df = pd.read_parquet(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4557a370-47ac-4762-ab41-b3dabb6e678c",
   "metadata": {},
   "source": [
    "The ***target features*** (the features that we are trying to predict with the machine learning model) are <>. Data from <> ***input features*** to the model. \n",
    "\n",
    "#### Explore target features\n",
    "\n",
    "Let's now explore just the target features at Blackhawk.  \n",
    "\n",
    "\n",
    "> **Instructions**\n",
    "> \n",
    "> Execute the two cells below.\n",
    "> \n",
    "> In the <> plotting widget, select the environmental variable and plot type from the dropdowns, then select Plot to reveal the plot.\n",
    ">\n",
    "> Repeat for any and all variables you want to explore to better understand the data at the Blackhawk gage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9534524",
   "metadata": {},
   "source": [
    "Annual Comparison units:\n",
    "\n",
    "When measuring streamflow, CFS (cubic feet per second) represents an instantaneous flow rate at a specific moment in time. When we sum daily CFS values across a year, we're no longer dealing with a rate but with a volume of water that has passed through the stream over time. This is why hydrologists use \"CFS-days\" as the unit - it accurately represents the integration of flow rate (CFS) over a time period (days). One CFS-day equals 86,400 cubic feet of water, which is the volume of water flowing at a rate of 1 cubic foot per second for an entire day. Using \"summed CFS\" would be dimensionally incorrect because summing rates doesn't maintain the same units; the time component needs to be accounted for in the final measurement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb05b604",
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis_tech import blackhawk_gage_dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9581a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb52de2b5703479ab3d1b0c70db49d7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<h3>Blackhawk Gage Hydrograph Dashboard</h3>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fd6815473f948e69a26d1f01538efb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Plot Type:', options=('Histogram', 'Annual Time Series', 'Annual Comparison'), value='Hiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4f28a0b29a14f8690f642e4f0c4883e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='primary', description='Generate Plot', style=ButtonStyle(), tooltip='Click to generate thâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cd5dc1869f644ac8f221b9edf7962ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "blackhawk_gage_dashboard(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ba0556d7-3f62-486a-8940-85395948e0be",
   "metadata": {},
   "source": [
    "#### Explore input features\n",
    "\n",
    "Now we will explore the ***input features***. Below is a map of where the stations are located in relation to MITC. Western North Carolina is a part of the Appalachian Mountains in the eastern United States, so stations are located at a variety of elevations. To further explore the terrain in the area, click the image below to open an interactive 3D map.   \n",
    "\n",
    "<center><a href=\" \" target=\"blank\"><img src=\" \" width=\"500 px\"></a><br>\n",
    "<i>Click to open interactive map</i></center>\n",
    "\n",
    "> **Instructions**\n",
    "> \n",
    "> Execute the two cells below.\n",
    ">\n",
    "> In the <> plotting widget, \n",
    ">\n",
    "> Repeat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68121f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis_tech import discharge_dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81b0e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "074879ec55fb48d3a228d9c6e0f03850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<h3>Hydrograph Stations Dashboard</h3>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8a568b7dc214572a44d2e79b63d369a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Location:', options=(('Georgetown', 'daily_mean_discharge_LEAV_GTOWN'), ('West Fork at Eâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ade2f8f1369d4db48e17d2df5356458d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Plot Type:', options=('Histogram', 'Annual Time Series', 'Annual Comparison'), value='Hiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88ee14f0dc9145f5aba15c8ef7c05131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='primary', description='Generate Plot', style=ButtonStyle(), tooltip='Click to generate thâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed81ee365e9b4f468e02f59f2774c6a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "discharge_dashboard(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c12f3e",
   "metadata": {},
   "source": [
    "#### Compare stations\n",
    "Intro\n",
    "\n",
    "<center><a href=\"https://elearning.unidata.ucar.edu/dataeLearning/Cybertraining/analysis/media/wellcorrelated.png\" target=\"blank\"><img src=\"https://elearning.unidata.ucar.edu/dataeLearning/Cybertraining/analysis/media/wellcorrelated.png\" width=\"200 px\"></a> <a href=\"https://elearning.unidata.ucar.edu/dataeLearning/Cybertraining/analysis/media/notwellcorrelated.png\" target=\"blank\"><img src=\"https://elearning.unidata.ucar.edu/dataeLearning/Cybertraining/analysis/media/notwellcorrelated.png\" width=\"200 px\"></a><br><i>Click to enlarge</i></center>\n",
    "\n",
    "The comparison plot grid displays histograms where the x- and y-axes are the same streamgage. These are the same histograms that you plotted previously, displaying the distribution of all values at that gage. \n",
    "\n",
    "> **Instructions**\n",
    "> \n",
    "> Execute the two cells below.\n",
    ">\n",
    "> In the Comparison Plot plotting widget\n",
    "> \n",
    "> Repeat for any and all variables you want to explore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71307df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "from analysis_tech import discharge_pairplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70715504",
   "metadata": {},
   "outputs": [],
   "source": [
    "discharge_pairplot(df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49eb31c-c0cf-477d-a771-282d49442189",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "<p class=\"admonition-title\" style=\"font-weight:bold\">Exercise 2b</p>\n",
    "    <p>Open your <b>Machine Learning Model Handbook</b> to Exercise 2b. Then describe your exploratory data analysis of any target and input features of note. Include the following:\n",
    "    <ul>\n",
    "        <li>Do variables follow diurnal or annual patterns generally as expected?</li>\n",
    "        <li>Do the variables have the expected ranges of values? Do any variables appear to include major outliers?</li>\n",
    "        <li>Which stations appear to be most correlated to the variables at Mt Mitchell? Why?</li>\n",
    "        <li>Include any <i>important</i> plots to illustrate your conclusions. Limit yourself to 5 plots. <br><i>To copy a plot image, hold shift, right click on the image, then select Copy.</i></li>\n",
    "    </ul>\n",
    "    </p>\n",
    "</div>\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2179f158-8f6b-45f3-ab00-aa889b092160",
   "metadata": {},
   "source": [
    "### Part 2c: Create a data splitting strategy\n",
    "\n",
    "Next we create a data splitting strategy. Data splitting refers to the process of dividing data into three groups: training, validation, and testing. Each of these groups represent a part of the iterative process for machine learning model development. \n",
    "\n",
    "- Training data is the largest subset, usually around 60-80% of the total data, and is used to initially train the model. \n",
    "- Validation data is roughly 10-20% of the total data, and is used to validate the effectiveness of the training process. \n",
    "- Testing data is also roughly 10-20% of the total data, and is used to test the final refined model before using it on new, unseen data.\n",
    "\n",
    "< special yearly considerations >\n",
    "\n",
    "Each group should be separate to ensure no single group will bias the model. In this model, the data will be randomly split into these groups, but you decide the proportions of data for each group. Input your percentages in the blanks below, ensuring all percentages equal 100%.\n",
    "\n",
    "> **Instructions**\n",
    "> \n",
    "> Execute the two cells below.\n",
    ">\n",
    "> In the Dataset Split Percentages widget,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060ba5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from analysis_tech import year_selection_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a85171",
   "metadata": {},
   "outputs": [],
   "source": [
    "widget, get_years = year_selection_widget()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7aa6420-48c4-44d5-a6a2-3a9fa6c32db8",
   "metadata": {},
   "source": [
    "> **Instructions**\n",
    "> \n",
    "> Execute the three cells below to execute the functions to split the data according to the percentages you submitted above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d1273d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is used to grab the values from the widget above (no need to change)\n",
    "years = get_years()\n",
    "training = years['training']\n",
    "validation = years['validation']\n",
    "testing = years['testing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e9dbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis_tech import split_data_temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4547defa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the function\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, = split_data_temporal(df,\n",
    "                                                                    train_years=training,\n",
    "                                                                    val_years=validation,\n",
    "                                                                    test_years=testing,\n",
    "                                                                    target_column='daily_mean_discharge_N_BLKHAWK')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9510216-b184-4de8-96a6-965f2a5042f1",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "<p class=\"admonition-title\" style=\"font-weight:bold\">Exercise 2c</p>\n",
    "    <ul>\n",
    "        <li><b>In your Machine Learning Model Handbook Exercise 2c,</b> input your data splitting strategy. </li>\n",
    "    </ul>\n",
    "</div>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055833d1-35ab-4553-935a-766209357f72",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b94e17c2-14c8-400e-9882-1016a33d888c",
   "metadata": {},
   "source": [
    "## Part 3: Model Development\n",
    "Next begins the iterative process of creating, evaluating, and refining your machine learning model. You will start with an initial model, and keep track of your subsequent trials in your Machine Learning Model Handbook. \n",
    "<center><a href=\"https://elearning.unidata.ucar.edu/dataeLearning/Cybertraining/analysis/media/RevisedFull_NOPROCESS_.png\" target=\"blank\"><img src=\"https://elearning.unidata.ucar.edu/dataeLearning/Cybertraining/analysis/media/RevisedFull_NOPROCESS_.png\"></a><br><i>Click to enlarge</i></center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc10b05e-e441-4af5-b7b5-e925294cf261",
   "metadata": {},
   "source": [
    "### Part 3a: Choose Algorithm\n",
    "First, you will choose an algorithm to train. You have two options: the *MultiXGBRegressor* and the *MultiLinearRegressor*. Both have pros and cons for this task. Choose one for your initial model, but you may choose to test the other algorithm in subsequent trials. \n",
    "\n",
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">About the Algorithms</p>\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">MultiXGBRegressor (XGBoost)</p>\n",
    "    <ul>\n",
    "        <li>Handles a Wide Range of Data Distributions: XGBoost is capable of modeling both linear and non-linear relationships, making it suitable for data with complex, varied distributions.</li>\n",
    "        <li>Prone to Overfitting: XGBoost can easily overfit to training data, especially when the dataset is small or noisy. This may lead to poor generalizations when making predictions on new data. </li>\n",
    "    </ul>\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">MultiLinearRegressor</p>\n",
    "    <ul>\n",
    "        <li>Simple and Interpretable: As a linear model, it is easy to understand and interpret within the context of the physical world, making it a great choice for finding clear relationships between features and predictions.</li>\n",
    "        <li>Struggles with Non-Uniform Data Distributions: For datasets with non-linear patterns or skewed distributions, multiple linear regression may fail to capture the underlying patterns, leading to biased or inaccurate predictions.</li>\n",
    "</div>\n",
    "\n",
    "> **Instructions**\n",
    "> \n",
    "> Execute the two cells below.\n",
    ">\n",
    "> After executing `algorithm_selection()`, select the corresponding button to select your desired algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14e8307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports needed to run the machine learning workflow\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "import time \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from analysis_tech import algorithm_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095e21a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_algo = algorithm_selection()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "18b99dcf-1fa1-4e03-b826-492e5b71fb91",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Part 3b: Choose input features\n",
    "\n",
    "Given your data exploration, you must now choose the input features to the algorithm you just selected. You may choose as many input features as you'd like, however, recall that more features does not always create a better model. Think strategically based on the evidence. \n",
    "\n",
    "<center><a href=\" \" target=\"blank\"><img src=\" \" width=\"500 px\"></a><br>\n",
    "<i>Click to open interactive map</i></center><br>\n",
    "\n",
    "> **Instructions**\n",
    "> \n",
    "> Execute the two cells below.\n",
    ">\n",
    "> After executing `create_station_selector()`, select the stations you would like to use to train your model. You may select as many or as few as you consider necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9edb193",
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis_tech import station_selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de3be7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_selector = station_selector()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7c1f45-54ea-4600-8563-f9d2e429bd6e",
   "metadata": {},
   "source": [
    "> **Instructions**\n",
    "> \n",
    "> Execute the cell below to commit your station selection. The output will also be used in describing subsequent evaluation metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0c9b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get selected stations at any time:\n",
    "def get_selected_stations(selector):\n",
    "    return [station for station, checkbox in selector.items() if checkbox.value]\n",
    "\n",
    "selected = get_selected_stations(station_selector)\n",
    "selected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68eeb52",
   "metadata": {},
   "source": [
    "This next block of code takes the full dataset and removes (filters) any stations that were not selected above. We do this for all groups (training, validation, and testing). \n",
    "\n",
    "<br>\n",
    "\n",
    "> **Instructions**\n",
    "> \n",
    "> Execute the two cells below. In the printout display, you will see the number of features (columns) in the original dataset, and the number of features in the filtered dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de1e99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis_tech import filter_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b094c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_filtered     = filter_dataframe(X_train,     selected)\n",
    "X_val_filtered       = filter_dataframe(X_val,       selected)\n",
    "X_test_filtered      = filter_dataframe(X_test,      selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fbcd3e-bd91-4b20-9bb4-d354926e5472",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Part 3c: Train the Algorithm\n",
    "\n",
    "The training process is what transforms the machine learning algorithm into a supervised machine learning model. The cells below start the training process with all the decisions you previously made. \n",
    "\n",
    "> **Instructions**\n",
    "> \n",
    "> Execute the two cells below.\n",
    ">\n",
    "> After executing `train_button()`, select the Train Algorithm button to initiate the training process. A progress printout will display below the button while the process runs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a388a0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis_tech import train_button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9e11f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_choice = selected_algo()\n",
    "trained_model = train_button(model_choice, X_train_filtered, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61c36ec-46d9-4d79-ade1-55bf639cabae",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Part 3d: Validate the Model\n",
    "\n",
    "The validation step uses validation data to evaluate how well the training process performed. By using a separate dataset to evaluate performance, we get a better sense of how well the model can generalize to new inputs. We focus on two main evaluation metrics: Root Mean Square Error (RMSE) and RÂ². \n",
    "\n",
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">About the Evaluation Metrics</p>\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">Root Mean Square Error (RMSE)</p>\n",
    "    <ul>\n",
    "        <li>A measure of how large a typical prediction error is</li>\n",
    "        <li>Reports the typical magnitude of error in the original units (degrees, %, mph, etc)</li>\n",
    "        <li>The closer to 0, the better the model accuracy</li>\n",
    "        <li>Better reflects the accuracy of predictions in real-world situations</li>\n",
    "        <li>Dependent on the range of values (scale) of the dataset, making comparisons among variables more difficult</li>\n",
    "    </ul>\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">RÂ²</p>\n",
    "    <ul>\n",
    "        <li>A measure of how well the model explains the variation in the dataset</li>\n",
    "        <li>Uses a standardized scale (0-1) for comparing models across different trials</li>\n",
    "            <ul>\n",
    "                <li>In some cases, RÂ² may be negative. This means that the model made a prediction worse than the dataset average (or climatology prediction).</li>\n",
    "            </ul>\n",
    "        <li>The closer to 1, the better the model accuracy</li>\n",
    "        <li>Assumes that the input data have a linear relationship</li>\n",
    "        <li>Only measures correlation among input data, cannot distinguish good and bad predictions in the real world</li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "\n",
    "> **Instructions**\n",
    "> \n",
    "> Execute the two cells below.\n",
    ">\n",
    "> After executing `model_eval`, your model's validation metrics will appear below as a printout. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66842084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Python libraries that calculate the evaluation metrics\n",
    "import numpy as np\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score, mean_squared_error\n",
    "\n",
    "from analysis_tech import model_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0ff68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eval(trained_model(), X_test_filtered, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f3e964-4f0a-44d5-baa1-65b9c9a4d169",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Part 3e: Evaluate and Refine the Model\n",
    "\n",
    "Examine the results of the model validation. What do each mean? Could they be improved? Review the descriptions of the evaluation metrics, then complete the next exercise. \n",
    "\n",
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "<p class=\"admonition-title\" style=\"font-weight:bold\">Exercise 3e</p>\n",
    "    <p>Open your <b>Machine Learning Model Handbook</b> to Exercise 3e. </p>\n",
    "    <p>Paste your validation evaluation metrics in the designated box. </p>\n",
    "    <p>Then describe the results of your initial model validation. Include the following:</p>\n",
    "    <ul>\n",
    "        <li>Which variables have favorable evaluation metrics? Which variables donâ€™t perform as well?</li>\n",
    "        <li>How do you interpret these statistics in the context of the physical world?</li>\n",
    "        <li>What changes will you make to try to improve these statistics in the next iteration?</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4c6653-d035-4415-b953-962328ce1e73",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Part 3f: Iterative Refinement Trials\n",
    "\n",
    "Your first trial is complete! Now you'll create new trials to improve the evaluation metrics from the validation phase. You may complete as many trials as you like until you are satisfied with the evaluation metrics, or they no longer improve with new trials. \n",
    "\n",
    "> **Instructions**\n",
    "> \n",
    "> Execute the code cells below, selecting your desired model configurations after executing each cell.\n",
    "> \n",
    "> After each new trial, you will copy the validation metrics in your handbook document. See **Exercise 3f**.\n",
    ">\n",
    "> You may complete as many trials in this section (3f) as you like until you are satisfied with the evaluation metrics, or they no longer improve with new trials. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9c160b-404d-4447-acdd-eb4d93027bfd",
   "metadata": {},
   "source": [
    "#### New trial: Choose algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dbcb1c-5319-40f4-9b9c-3d6fe3bf2e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_algo = algorithm_selection()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423ab52a-3957-4660-a178-e5824a58c636",
   "metadata": {},
   "source": [
    "#### New trial: Choose input features\n",
    "\n",
    "<center><a href=\" \" target=\"blank\"><img src=\" \" width=\"500 px\"></a><br>\n",
    "<i>Click to open interactive map</i></center><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b12ae6-e2ab-4e2f-b0ae-736b84e2b967",
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis_tech import station_selector\n",
    "stations = station_selector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6ca79a-1d43-457c-9997-9eef3d0bc1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute this cell after selecting stations\n",
    "selected = get_selected_stations(stations)\n",
    "\n",
    "X_train_filtered     = filter_dataframe(X_train,     selected)\n",
    "X_val_filtered       = filter_dataframe(X_val,       selected)\n",
    "X_test_filtered      = filter_dataframe(X_test,      selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98ed0d1-3526-45b3-8649-50aada35023d",
   "metadata": {},
   "source": [
    "#### New trial: Train algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7ab4b7-cdb3-4a8b-bbab-f1b5776b1639",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_choice = selected_algo()\n",
    "trained_model = train_button(model_choice, X_train_filtered, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ded4e98-f356-4000-b209-e7b98a075d52",
   "metadata": {},
   "source": [
    "#### New trial: Validate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fe5c25-b1f9-437e-bf6f-dc97ed8e1d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eval(trained_model(), X_val_filtered, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ec7a1c-93ad-46e3-80cb-a7aa924aba84",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "<p class=\"admonition-title\" style=\"font-weight:bold\">Exercise 3f</p>\n",
    "    <ul>\n",
    "        <li><b>In your Machine Learning Model Handbook Exercise 3f,</b> paste the full output of each of your validation trials, one per box. </li>\n",
    "        <li>You may complete as many trials as you like until you are satisfied with the evaluation metrics, or they no longer improve with new trials. When complete, move on to the next part below. </li>\n",
    "    </ul>\n",
    "</div>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37323e1-2a75-4f9b-9071-a3e79cd78dd5",
   "metadata": {},
   "source": [
    "### Part 3g: Test Model\n",
    "\n",
    "<div class=\"alert alert-warning\" role=\"alert\">\n",
    "<p class=\"admonition-title\" style=\"font-weight:bold\">Important</p>\n",
    "    For testing, your model needs to be in a state with your desired algorithm and input feature stations. If you haven't already, go back and run through the cells in Part 3f with your final choices one last time. This ensures that your final testing process will be executed with your desired choices. \n",
    "</div>\n",
    "<br>\n",
    "At this point, you have a trained model with validation metrics you are satisfied with. Next, it's time to test the model on brand new data: the testing dataset. The testing process mimics how the model would be used in a real-world process in a final, unbiased way. \n",
    "<br><br>\n",
    "Testing looks very similar to validation. The model makes predictions based on the input features in the testing dataset, we calculate RMSE and RÂ² as the testing metrics. \n",
    "\n",
    "> **Instructions**\n",
    "> \n",
    "> Execute the cell below.\n",
    ">\n",
    "> After executing `model_eval`, your model's testing metrics will appear below as a printout. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c4350a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eval(trained_model(), X_test_filtered, y_test, eval_type='Testing')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e20b35-3933-457a-b454-925143761974",
   "metadata": {},
   "source": [
    "### Part 3h: Evaluate and Justify\n",
    "\n",
    "< comparison of predictions > \n",
    "\n",
    "> **Instructions**\n",
    "> \n",
    "> Execute "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378da27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "y_pred = trained_model().predict(X_test_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e1bc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate absolute error\n",
    "abs_error = np.abs(y_pred - y_test)\n",
    "\n",
    "# Calculate percentage of predictions with error of 5 CFS or less\n",
    "within_5cfs = abs_error <= 5\n",
    "percent_within_5cfs = 100 * np.sum(within_5cfs) / len(abs_error)\n",
    "print(f\"Percentage of predictions within 5 CFS of actual: {percent_within_5cfs:.2f}%\")\n",
    "\n",
    "# Calculate percentage of predictions with error of 10 CFS or less\n",
    "within_10cfs = abs_error <= 10\n",
    "percent_within_10cfs = 100 * np.sum(within_10cfs) / len(abs_error)\n",
    "print(f\"Percentage of predictions within 10 CFS of actual: {percent_within_10cfs:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7b123a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as colors\n",
    "from matplotlib.ticker import SymmetricalLogLocator\n",
    "\n",
    "# Calculate absolute and percent errors\n",
    "abs_error = y_pred - y_test\n",
    "percent_error = 100 * abs_error / y_test  # Percent error relative to actual values\n",
    "\n",
    "# Create figure with two subplots stacked vertically\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 12), sharex=True)\n",
    "\n",
    "# Predicted vs Actual plot with very low alpha\n",
    "ax1.scatter(y_test, y_pred, color='blue', alpha=0.03)  # Reduced alpha to 0.03\n",
    "\n",
    "# Add perfect prediction line\n",
    "min_val = -2  # Start at -2\n",
    "max_val = max(y_test.max(), y_pred.max())\n",
    "ax1.plot([min_val, max_val], [min_val, max_val], 'k--')\n",
    "\n",
    "# Configure first plot\n",
    "ax1.set_title('Predicted vs Actual Daily Mean Discharge')\n",
    "ax1.set_ylabel('Predicted Discharge (cfs)')\n",
    "ax1.grid(True)\n",
    "ax1.set_xlim(min_val, max_val)  # Set x-axis to start at -2\n",
    "\n",
    "# Percent Error vs Actual values plot with very low alpha\n",
    "ax2.scatter(y_test, percent_error, color='green', alpha=0.03)  # Reduced alpha to 0.03\n",
    "ax2.axhline(y=0, color='k', linestyle='--')\n",
    "\n",
    "# Set symmetric log scale for y-axis in percent error plot\n",
    "linthresh = 1.0  # Linear threshold\n",
    "ax2.set_yscale('symlog', linthresh=linthresh)\n",
    "\n",
    "# Find a good limit for the y-axis based on data\n",
    "max_error = max(abs(percent_error.min()), abs(percent_error.max()))\n",
    "rounded_max = 10**(np.ceil(np.log10(max_error)))\n",
    "ax2.set_ylim(-rounded_max, rounded_max)\n",
    "\n",
    "# Configure second plot\n",
    "ax2.set_title('Percent Error vs Actual Values (Symmetric Log Scale)')\n",
    "ax2.set_xlabel('Actual Discharge (cfs)')\n",
    "ax2.set_ylabel('Percent Error (%)')\n",
    "ax2.grid(True)\n",
    "ax2.set_xlim(min_val, max_val)  # Ensure the second plot matches (though sharex should handle this)\n",
    "\n",
    "# Add basic statistics\n",
    "mean_percent_error = np.mean(np.abs(percent_error))  # Mean absolute percent error\n",
    "ax2.text(0.02, 0.95, f\"MAPE: {mean_percent_error:.2f}%\", transform=ax2.transAxes,\n",
    "         bbox=dict(facecolor='white', alpha=0.7))\n",
    "\n",
    "# Add RMSE to the first plot\n",
    "rmse = np.sqrt(np.mean((y_pred - y_test)**2))\n",
    "ax1.text(0.02, 0.95, f\"RMSE: {rmse:.2f} cfs\", transform=ax1.transAxes,\n",
    "         bbox=dict(facecolor='white', alpha=0.7))\n",
    "\n",
    "# Adjust layout\n",
    "fig.suptitle('Daily Mean Discharge (USGS 00060) Model Evaluation', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.95, hspace=0.3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787368fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with two subplots side by side\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 7))\n",
    "\n",
    "# First hexbin plot (0-100 range) with log scale\n",
    "hb1 = ax1.hexbin(x=y_test, y=y_pred, gridsize=25, bins='log', cmap=\"Blues\", \n",
    "                extent=[0, 100, 0, 100], mincnt=1)\n",
    "ax1.set_xlim(0, 100)\n",
    "ax1.set_ylim(0, 100)\n",
    "\n",
    "# Perfect prediction line for first plot\n",
    "ax1.plot([0, 100], [0, 100], 'k--', alpha=0.7)\n",
    "\n",
    "# Calculate RMSE for visible range (0-100)\n",
    "visible_mask1 = (y_test <= 100) & (y_pred <= 100)\n",
    "visible_rmse1 = np.sqrt(np.mean((y_pred[visible_mask1] - y_test[visible_mask1])**2))\n",
    "ax1.text(0.05, 0.95, f\"RMSE (0-100 cfs): {visible_rmse1:.2f} cfs\", \n",
    "         transform=ax1.transAxes, bbox=dict(facecolor='white', alpha=0.7))\n",
    "\n",
    "# Labels for first plot\n",
    "ax1.set_xlabel('Actual Discharge (cfs)')\n",
    "ax1.set_ylabel('Predicted Discharge (cfs)')\n",
    "ax1.set_title('Discharge: 0-100 cfs')\n",
    "\n",
    "# Add colorbar for first plot\n",
    "cbar1 = fig.colorbar(hb1, ax=ax1)\n",
    "cbar1.set_label('Count (log scale)')\n",
    "\n",
    "# Second hexbin plot (0-20 range) with log scale\n",
    "hb2 = ax2.hexbin(x=y_test, y=y_pred, gridsize=25, bins='log', cmap=\"Blues\", \n",
    "                extent=[0, 20, 0, 20], mincnt=1)\n",
    "ax2.set_xlim(0, 20)\n",
    "ax2.set_ylim(0, 20)\n",
    "\n",
    "# Perfect prediction line for second plot\n",
    "ax2.plot([0, 20], [0, 20], 'k--', alpha=0.7)\n",
    "\n",
    "# Calculate RMSE for visible range (0-20)\n",
    "visible_mask2 = (y_test <= 20) & (y_pred <= 20)\n",
    "visible_rmse2 = np.sqrt(np.mean((y_pred[visible_mask2] - y_test[visible_mask2])**2))\n",
    "ax2.text(0.05, 0.95, f\"RMSE (0-20 cfs): {visible_rmse2:.2f} cfs\", \n",
    "         transform=ax2.transAxes, bbox=dict(facecolor='white', alpha=0.7))\n",
    "\n",
    "# Labels for second plot\n",
    "ax2.set_xlabel('Actual Discharge (cfs)')\n",
    "ax2.set_ylabel('Predicted Discharge (cfs)')\n",
    "ax2.set_title('Discharge: 0-20 cfs')\n",
    "\n",
    "# Add colorbar for second plot\n",
    "cbar2 = fig.colorbar(hb2, ax=ax2)\n",
    "cbar2.set_label('Count (log scale)')\n",
    "\n",
    "# Overall title\n",
    "fig.suptitle('Predicted vs Actual Daily Mean Discharge (USGS 00060)', fontsize=14, y=0.98)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d4f576-7b33-4eb8-a958-0470baf0565b",
   "metadata": {},
   "source": [
    "#### Your final decision\n",
    "\n",
    "Given all your evaluation, it's time to make a final decision on whether you believe this model provides sufficient skill for the needs of the situation. Go back and review your problem statement. Does this model deliver the results needed?\n",
    "\n",
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "<p class=\"admonition-title\" style=\"font-weight:bold\">Exercise 3h</p>\n",
    "    <p>Open your <b>Machine Learning Model Handbook</b> to Exercise 3h.</p>\n",
    "    <p>Paste your testing evaluation metrics in the designated box. </p>\n",
    "    <p>Then  make a final decision on whether this model delivers on the results needed with supporting justification. Include the following:\n",
    "    <ul>\n",
    "        <li>Which environmental variables had the best evaluation metrics? List some physical scientific reasons why this may be the case.</li>\n",
    "        <li>Is this model ready for use in the real world? Why or Why not?</li>\n",
    "        <li>What other possible changes could further improve this model?</li>\n",
    "    </ul>\n",
    "    </p>\n",
    "</div>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9537e8b9-9d60-4e1b-b40e-ee1126c0bdc9",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "Scientific research rarely yields a simple and straightforward right answer. Instead, scientists analyze evidence, compare it to known physical processes, and make informed recommendations based on data and statistics. As you learned in *Machine Learning Foundations in the Earth System Sciences*, machine learning is not an exact science, rather, it generates approximations from large datasets. This makes evaluating model quality complex. What one scientist considers a high-performing model may be insufficient to another. What matters most is your ability to justify your results within the context of physical science and the real-world stakes. As you continue your studies, remember that these models are not just numbers. They are representations of the physical world."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98948be-d20b-432d-8205-ea9b7c0b3586",
   "metadata": {},
   "source": [
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2149feb2-3ac0-4dd0-9877-53baff421aeb",
   "metadata": {},
   "source": [
    "#### Acknowledgements\n",
    "\n",
    "This work was supported by NSF Unidata under award #2319979 from the US National Science Foundation. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation. \n",
    "\n",
    "We thank the <a href=\"https://www.usgs.gov/\" target=\"blank\">USGS</a> for contributing <a href=\" \" target=\"blank\">data</a> and media to this project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3bff7d-7deb-4247-a482-dc4e328800ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312geo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
