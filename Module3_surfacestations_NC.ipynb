{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9805bfd2-b31d-4b2f-b325-a409c27f96c7",
   "metadata": {},
   "source": [
    "<img src=\"https://elearning.unidata.ucar.edu/dataeLearning/Cybertraining/analysis/media/NSF-Unidata_lockup_vertical_2023.png\" width=\"150px\" align=\"right\">\n",
    "\n",
    "# Machine Learning Analysis in the Earth Systems Sciences\n",
    "\n",
    "In this module, you are tasked with planning, implementing, and evaluating a machine learning solution for a real-world scenario. Given pre-configured code blocks and prepared data, you will create a problem statement, explore the data, experiment with model development, and ultimately make a recommendation on the utility of machine learning for your scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e3747f-a6cf-4326-9e5c-67117de117b9",
   "metadata": {},
   "source": [
    "# Damaged weather station in western North Carolina\n",
    "\n",
    "Play the video below to learn about the situation at hand.\n",
    "\n",
    "<video width=\"600\" controls>\n",
    "  <source src=\"https://elearning.unidata.ucar.edu/dataeLearning/Cybertraining/analysis/media/stationsintrovideo_i1_nojupyterdemo.mp4\" type=\"video/mp4\">\n",
    "</video>\n",
    "\n",
    "<a href=\"https://www.google.com/url?q=https://docs.google.com/document/d/e/2PACX-1vRfYtUFjLVfNadQ0nvUv4E8MzfaXmQwt_WcP0haCo5bH1J0zGZiupiJz7XuLsun2BqN-g_ubbACpx6p/pub&sa=D&source=docs&ust=1738596555923034&usg=AOvVaw2xJ1FEg1SflwC6i3P5uQqD\" target=\"blank\">Transcript</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5cad94-efb5-4291-830e-64a8ad7ea483",
   "metadata": {},
   "source": [
    "Now you will begin the process of following the supervised machine learning model framework to address this task. Starting with problem framing.\n",
    "<center><a href=\"https://elearning.unidata.ucar.edu/dataeLearning/Cybertraining/analysis/media/RevisedFull_NOPROCESS_.png\" target=\"blank\"><img src=\"https://elearning.unidata.ucar.edu/dataeLearning/Cybertraining/analysis/media/RevisedFull_NOPROCESS_.png\"></a><br><i>Click to enlarge</i></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8ffff5-7731-4142-bd98-d9f5db95dd13",
   "metadata": {},
   "source": [
    "## Part 1: Problem Framing\n",
    "\n",
    "Based on the information provided in the video, which *type* of machine learning analysis is most appropriate for this scenario? Select the corresponding button to check your selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bee4cd7-65d4-47b5-b461-48d17890a0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the tools that python is calling, similar to a matlab toolbox\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, HTML, IFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58bb007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDE THIS\n",
    "output = widgets.Output()\n",
    "\n",
    "classification_button = widgets.Button(\n",
    "   description='Classification',\n",
    "   layout=widgets.Layout(width='200px', height='200px', margin='10px')\n",
    ")\n",
    "\n",
    "regression_button = widgets.Button(\n",
    "   description='Regression',\n",
    "   layout=widgets.Layout(width='200px', height='200px', margin='10px')\n",
    ")\n",
    "\n",
    "def classification_clicked(b):\n",
    "    with output:\n",
    "        clear_output(wait=True)\n",
    "        display(HTML(\"\"\"\n",
    "            <div class=\"alert alert-info\" role=\"feedback\">\n",
    "                <p class=\"admonition-title\" style=\"font-weight:bold\">Incorrect</p>\n",
    "            \t<p>Classification tasks work for scenarios that require classifying data into categories. \n",
    "                This task needs a <i>numerical value </i>for output, and therefore requires a different approach.</p>\n",
    "            </div>\n",
    "        \"\"\"))\n",
    "\n",
    "def regression_clicked(b):\n",
    "    with output:\n",
    "        clear_output(wait=True)\n",
    "        display(HTML(\"\"\"\n",
    "            <div class=\"alert alert-info\" role=\"feedback\">\n",
    "                <p class=\"admonition-title\" style=\"font-weight:bold\">Correct</p>\n",
    "            \t<p>This scenario requires a numerical output, so we will use a regression algorithm for this scenario.</p>\n",
    "            </div>\n",
    "        \"\"\"))\n",
    "\n",
    "# event handlers\n",
    "classification_button.on_click(classification_clicked)\n",
    "regression_button.on_click(regression_clicked)\n",
    "\n",
    "buttons = widgets.HBox([classification_button, regression_button])\n",
    "\n",
    "\n",
    "display(buttons, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c41fcf-e3c0-488e-9c71-de6c5d088b12",
   "metadata": {},
   "source": [
    "As a part of the problem framing step, we must answer a series of questions to ensure we're creating the best solution for this scenario. \n",
    "\n",
    "***Does a simpler solution exist?***\n",
    "> From the video, we know that you have already completed a preliminary analysis that averaged values from nearby stations to Mt Mitchell. While these results showed some skill, there is room for improvement. \n",
    "\n",
    "***Can machine learning requirements be met?***\n",
    "> The NC ECONet data provider has decades of hourly data available from several weather stations. This is sufficient for your model. \n",
    "\n",
    "***Which scientific question should be answered?***\n",
    "> You will answer this question in **Exercise 1** below. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd95337-12f5-4e9b-a786-979ebad08b20",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "<p class=\"admonition-title\" style=\"font-weight:bold\">Exercise 1</p>\n",
    "    <p>In your <b>Machine Learning Model Handbook</b>, type the scientific question to be answered for this situation.</p>\n",
    "    <p>GENERAL RUBRIC TBD</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40af46bf-61eb-4cdd-8701-aa774ffce5af",
   "metadata": {},
   "source": [
    "## Part 2: Data Handling\n",
    "\n",
    "### Part 2a: Locate Data of Interest\n",
    "\n",
    "You will be using other stations in the <a href=\"https://econet.climate.ncsu.edu/\" target=\"blank\">NC ECONet</a> for this project. Your colleague is a <a href=\"https://www.mongodb.com/resources/basics/data-engineering#what-is-data-engineering\" target=\"blank\">data engineer</a> who has done much of the data preparation for you. They have prepared the following document to describe the nature of the dataset they are providing you for your model building work. \n",
    "\n",
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "### Metadata Document for Western North Carolina Weather Station Data\n",
    "\n",
    "#### General Information\n",
    "\n",
    "Dataset Name: Western NC Weather Station Time-Series Data\n",
    "\n",
    "Description: This dataset contains tabular time-series data collected from multiple weather stations in Western North Carolina. The data includes atmospheric and environmental variables recorded at hourly intervals.\n",
    "\n",
    "Date Range: January 1, 2015, to December 16, 2024\n",
    "\n",
    "Geographic Coverage: Western North Carolina \n",
    "\n",
    "Data Frequency: Hourly\n",
    "\n",
    "Last Updated: Jan 1, 2025\n",
    "\n",
    "#### Data Structure\n",
    "\n",
    "File Format: .parquet\n",
    "\n",
    "Number of Records: 69,760 per station per feature\n",
    "\n",
    "Columns (Features) \n",
    "\n",
    "- observation_datetime: Date and time of observation in UTC\n",
    "\n",
    "Columns (features) per Station (XXXX):\n",
    "\n",
    "- XXXX_airtemp_degF (Â°F): Air temperature measured at 2 meters above ground level\n",
    "- XXXX_windspeed_mph (mph): Average wind speed during the hour at 10 meters above ground level\n",
    "- XXXX_winddgust_mph (mph): Peak wind gust during the hour at 10 meters above ground level\n",
    "- XXXX_rh_percent (%): Average Relative humidity\n",
    "- XXXX_precip_in (in): Total precipitation accumulated in the hour\n",
    "\n",
    "Stations:\n",
    "\n",
    "- BEAR (Bearwallow Mountain)\n",
    "- BURN (Burnsville Tower)\n",
    "- FRYI (Frying Pan Mountain)\n",
    "- JEFF (Mount Jefferson Tower)\n",
    "- **MITC (Mount Mitchell State Park) - target station**\n",
    "- NCAT (North Carolina A&T University Research Farm)\n",
    "- SALI (Piedmont Research Station)\n",
    "- SASS (Sassafrass Mountain)\n",
    "- UNCA (University of North Carolina - Asheville Weather Tower)\n",
    "- WINE (Wayah Bald Mountain)\n",
    "\n",
    "<a href=\"https://econet.climate.ncsu.edu/\" target=\"blank\">More station info</a>\n",
    "\n",
    "#### Data Quality\n",
    "\n",
    "Missing Data: Missing data besides MITC was filled in using seasonal values and basic interpolation.\n",
    "\n",
    "Outlier Handling: No outlier handling was done. \n",
    "\n",
    "#### Data Provenance\n",
    "\n",
    "Source: North Carolina State Climate Office ECONet, <a href=\"https://econet.climate.ncsu.edu\" target=\"blank\">https://econet.climate.ncsu.edu/about/</a>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ce9319-3e5c-4632-a488-b777f93c9603",
   "metadata": {},
   "source": [
    "### Part 2b: Explore Data\n",
    "\n",
    "While your data engineer colleague prepared the data for your model and created the metadata document, you will still need to familiarize yourself with the data before you use it as input to a machine learning algorithm. In this step, you will take a closer look at the potential features for your model with a few plots. \n",
    "\n",
    "First, let's read the data into this workspace. The data resides on a remote THREDDS Data Server, which allows users to access data without manually downloading files to your computer. When you execute the code cell below, you will load the Python library `pandas` that includes all the tools for reading the data from the THREDDS Data Server and opening it in this workspace. \n",
    "\n",
    "*Executing the cell below may take a moment to complete.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d6c37c-c245-4006-9e15-2c3674b17da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pandas Python library that can interpret the data file\n",
    "import pandas as pd\n",
    "\n",
    "# Location of the data on the remote server\n",
    "file_path = 'https://thredds.ucar.edu/thredds/fileServer/cybertraining/CyberTraining_NC_ECOnet_data.parquet'\n",
    "\n",
    "# Read data into this workspace\n",
    "df = pd.read_parquet(file_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4557a370-47ac-4762-ab41-b3dabb6e678c",
   "metadata": {},
   "source": [
    "The ***target features*** (the features that we are trying to predict with the machine learning model) are temperature, relative humidity, wind speed, wind gust, and precipitation at the Mt. Mitchell station. All other station data are possible ***input features*** to the model. \n",
    "\n",
    "#### Explore target features\n",
    "\n",
    "Let's now explore just the target features at Mt. Mitchell. In the code cell below, you will import the necessary Python libraries and functions that power the plotting widget. The widget will load after executing the cell. \n",
    "\n",
    "In the plotting widget, select the environmental variable and plot type from the dropdowns, then select Plot to reveal the plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806a7318-4421-437d-875b-83c93b61a622",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# HIDE THIS\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Variable dropdown\n",
    "var_dropdown = widgets.Dropdown(\n",
    "    options=[\n",
    "        ('Temperature (F)', 'MITC_airtemp_degF'),\n",
    "        ('Average Wind Speed (mph)', 'MITC_windspeed_mph'),\n",
    "        ('Wind Gust (mph)', 'MITC_windgust_mph'),\n",
    "        ('Relative Humidity (%)', 'MITC_rh_percent'),\n",
    "        ('Precipitation (in)', 'MITC_precip_in')\n",
    "    ],\n",
    "    description='Variable:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Plot type dropdown\n",
    "plot_dropdown = widgets.Dropdown(\n",
    "    options=['Histogram', 'Time Series'],\n",
    "    description='Plot type:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Button for plotting\n",
    "plot_button = widgets.Button(description=\"Plot\")\n",
    "\n",
    "# Output widget to render plots\n",
    "output = widgets.Output()\n",
    "\n",
    "# Display widgets and output\n",
    "display(widgets.HTML(value=\"<h3>Mt. Mitchell</h3>\"), var_dropdown, plot_dropdown, plot_button, output)\n",
    "\n",
    "# Button click event handler\n",
    "def on_plot_button_click(b):\n",
    "    # Retrieve current selections\n",
    "    var_value = var_dropdown.value\n",
    "    var_label = var_dropdown.label\n",
    "\n",
    "    # Clear previous output\n",
    "    with output:\n",
    "        clear_output(wait=True)  # Clear the previous plot\n",
    "\n",
    "        # Generate the selected plot\n",
    "        if plot_dropdown.value == 'Histogram':\n",
    "            fig, ax = plt.subplots(1, 1, tight_layout=True)\n",
    "            ax.hist(df[var_dropdown.value], bins=30, color='skyblue', edgecolor='black')\n",
    "            ax.set_title(f\"Histogram of {var_dropdown.label} at Mt. Mitchell (MITC)\", fontsize=14)\n",
    "            ax.set_xlabel(var_dropdown.label)\n",
    "            ax.set_ylabel(\"Number of records\")\n",
    "            plt.show()\n",
    "        elif plot_dropdown.value == 'Time Series':\n",
    "            xdates = pd.to_datetime(df['observation_datetime'])\n",
    "            fig, ax = plt.subplots(1, 1, tight_layout=True)\n",
    "            ax.plot(xdates[::100], df[var_dropdown.value][::100], label=var_dropdown.label, color='orange')\n",
    "            ax.set_title(f\"Time Series of {var_dropdown.label} at Mt. Mitchell (MITC)\", fontsize=14)\n",
    "            ax.set_xlabel(\"Date\")\n",
    "            ax.set_ylabel(var_dropdown.label)\n",
    "            ax.xaxis.set_major_locator(mdates.YearLocator())\n",
    "            ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "            plt.show()\n",
    "\n",
    "# Attach the event handler to the button\n",
    "plot_button.on_click(on_plot_button_click)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ba0556d7-3f62-486a-8940-85395948e0be",
   "metadata": {},
   "source": [
    "#### Explore input features\n",
    "\n",
    "Now explore the ***input features***. Below is a map of where the stations are located in relation to MITC. Click on the image below to open an interactive map.\n",
    "\n",
    "<center><a href=\"https://elearning.unidata.ucar.edu/dataeLearning/Cybertraining/analysis/media/plotlystationmap.html\" target=\"blank\"><img src=\"https://elearning.unidata.ucar.edu/dataeLearning/Cybertraining/analysis/media/stationmap_plotly.png\"></a><br>\n",
    "<i>Click to open interactive map</i></center>\n",
    "\n",
    "After executing the cell below, select a station, variable, and type of plot, then select Plot to reveal the plot. \n",
    "\n",
    "To copy an image for pasting into your handbook, hold shift and right click on the image, then select Copy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe360a5-cc33-437d-bb91-9d683da09538",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# HIDE THIS\n",
    "var_dropdown = widgets.Dropdown(\n",
    "    options=[\n",
    "        ('Temperature (F)', 'airtemp_degF'),\n",
    "        ('Average Wind Speed (mph)', 'windspeed_mph'),\n",
    "        ('Wind Gust (mph)', 'windgust_mph'),\n",
    "        ('Relative Humidity (%)', 'rh_percent'),\n",
    "        ('Precipitation (in)', 'precip_in')\n",
    "    ],\n",
    "    description='Variable:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Plot type dropdown\n",
    "plot_dropdown = widgets.Dropdown(\n",
    "    options=['Histogram', 'Time Series'],\n",
    "    description='Plot type:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Station dropdown\n",
    "station_dropdown = widgets.Dropdown(\n",
    "    options=['BEAR', 'BURN', 'FRYI', 'JEFF', 'NCAT', 'SALI', 'SASS', 'UNCA', 'WINE'],\n",
    "    description='Station:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Button for plotting\n",
    "plot_button = widgets.Button(description=\"Plot\")\n",
    "\n",
    "# Output widget to render plots\n",
    "output = widgets.Output()\n",
    "\n",
    "# Display widgets and output\n",
    "display(widgets.HTML(value=\"<h3>Input Stations</h3>\"), station_dropdown, var_dropdown, plot_dropdown, plot_button, output)\n",
    "\n",
    "# Button click event handler\n",
    "def on_plot_button_click(b):\n",
    "    # Retrieve current selection\n",
    "    selected_var = f\"{station_dropdown.value}_{var_dropdown.value}\"\n",
    "\n",
    "    # Clear previous output\n",
    "    with output:\n",
    "        clear_output(wait=True)  # Clear the previous plot\n",
    "\n",
    "        # Generate the selected plot\n",
    "        if plot_dropdown.value == 'Histogram':\n",
    "            fig, ax = plt.subplots(1, 1, tight_layout=True)\n",
    "            ax.hist(df[selected_var], bins=30, color='skyblue', edgecolor='black')\n",
    "            ax.set_title(f\"Histogram of {var_dropdown.label} at {station_dropdown.value}\", fontsize=14)\n",
    "            ax.set_xlabel(var_dropdown.label)\n",
    "            ax.set_ylabel(\"Number of records\")\n",
    "            plt.show()\n",
    "        elif plot_dropdown.value == 'Time Series':\n",
    "            xdates = pd.to_datetime(df['observation_datetime'])\n",
    "            fig, ax = plt.subplots(1, 1, tight_layout=True)\n",
    "            ax.plot(xdates[::100], df[selected_var][::100], label=var_dropdown.label, color='orange')\n",
    "            ax.set_title(f\"Time Series of {var_dropdown.label} at {station_dropdown.value}\", fontsize=14)\n",
    "            ax.set_xlabel(\"Date\")\n",
    "            ax.set_ylabel(var_dropdown.label)\n",
    "            ax.xaxis.set_major_locator(mdates.YearLocator())\n",
    "            ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "            plt.show()\n",
    "\n",
    "# Attach the event handler to the button\n",
    "plot_button.on_click(on_plot_button_click)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c12f3e",
   "metadata": {},
   "source": [
    "#### Compare stations\n",
    "We can also plot direct comparisons of stations in our dataset by plotting data at each station in a grid of plots. In these comparison grids, the scatter plots display the observations at each station, for example, the temperature at MITC on the x-axis and the temperature at SASS on the y-axis. Stations that are well-correlated will show points that are generally clustered with very little spread. \n",
    "\n",
    "<center><a href=\"https://elearning.unidata.ucar.edu/dataeLearning/Cybertraining/analysis/media/wellcorrelated.png\" target=\"blank\"><img src=\"https://elearning.unidata.ucar.edu/dataeLearning/Cybertraining/analysis/media/wellcorrelated.png\" width=\"200 px\"></a> <a href=\"https://elearning.unidata.ucar.edu/dataeLearning/Cybertraining/analysis/media/notwellcorrelated.png\" target=\"blank\"><img src=\"https://elearning.unidata.ucar.edu/dataeLearning/Cybertraining/analysis/media/notwellcorrelated.png\" width=\"200 px\"></a><br><i>Click to enlarge</i></center>\n",
    "\n",
    "The grid displays histograms where the x- and y-axes are the same station. These are the same histograms that you plotted previously, displaying the distribution of all values at that station. \n",
    "\n",
    "As previous, you will execute the cell below to initialize the widget, then use the dropdown to select a variable and select Plot. To copy an image for pasting into your handbook, hold shift and right click on the image, then select Copy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245471e1-fb44-45ed-bdb2-3cb4399ede2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://elearning.unidata.ucar.edu/dataeLearning/Cybertraining/analysis/media/pairplot_\"\n",
    "\n",
    "# Dropdown widget\n",
    "var_dropdown = widgets.Dropdown(\n",
    "    options=[\n",
    "        ('Temperature (F)', 'airtemp_degF'),\n",
    "        ('Precipitation (in)', 'precip_in'),\n",
    "        ('Relative Humidity (%)', 'rh_percent'),\n",
    "        ('Wind Gust (mph)', 'windgust_mph'),\n",
    "        ('Average Wind Speed (mph)', 'windspeed_mph')\n",
    "    ],\n",
    "    description='Variable:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Button widget\n",
    "plot_button = widgets.Button(description=\"Plot\")\n",
    "\n",
    "# Output widget to display the selected image\n",
    "output = widgets.Output()\n",
    "\n",
    "def update_image(_):\n",
    "    \"\"\"Update the displayed image based on the selected variable.\"\"\"\n",
    "    selected_var = var_dropdown.value  # Get selected variable value\n",
    "    image_url = f\"{base_url}{selected_var}.png\"  # Construct the full image URL\n",
    "    \n",
    "    with output:\n",
    "        output.clear_output(wait=True)\n",
    "        display(HTML(\n",
    "            f'<center><i>Click to enlarge</i><br>'\n",
    "            f'<a href=\"{image_url}\" target=\"blank\">'\n",
    "            f'<img src=\"{image_url}\" width=\"600px\"></a></center>'\n",
    "        ))\n",
    "# Attach function to button click\n",
    "plot_button.on_click(update_image)\n",
    "\n",
    "# Display widgets\n",
    "display(var_dropdown, plot_button, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49eb31c-c0cf-477d-a771-282d49442189",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "<p class=\"admonition-title\" style=\"font-weight:bold\">Exercise 2b</p>\n",
    "    <p>In your <b>Machine Learning Model Handbook</b>, describe your exploratory data analysis of any target and input features of note. Include the following:\n",
    "    <ul>\n",
    "        <li>Do variables follow diurnal or annual patterns generally as expected?</li>\n",
    "        <li>Do the variables have the expected ranges of values? Do any variables appear to include major outliers?</li>\n",
    "        <li>Which stations appear to be most correlated to the variables at Mt Mitchell? Why?</li>\n",
    "        <li>Which variables do you think will be easiest to prdict with a machine learning model? Why?</li>\n",
    "        <li>Include any <i>important</i> plots to illustrate your conclusions. Limit yourself to 5 plots. <br><i>To copy a plot image, hold shift, right click on the image, then select Copy.</i></li>\n",
    "    </ul>\n",
    "    </p>\n",
    "    <p>GENERAL RUBRIC TBD</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2179f158-8f6b-45f3-ab00-aa889b092160",
   "metadata": {},
   "source": [
    "### Part 2c: Create a data splitting strategy\n",
    "\n",
    "Next we create a data splitting strategy. Data splitting refers to the process of dividing data into three groups: training, validation, and testing. Each of these groups represent a part of the iterative process for machine learning model development. \n",
    "\n",
    "- Training data is the largest subset, usually around 60-80% of the total data, and is used to initially train the model. \n",
    "- Validation data is roughly 10-20% of the total data, and is used to validate the effectiveness of the training process. \n",
    "- Testing data is also roughly 10-20% of the total data, and is used to test the final refined model before using it on new, unseen data.\n",
    "\n",
    "Each group should be separate to ensure no single group will bias the model. In this model, the data will be randomly split into these groups, but you decide the proportions of data for each group. Input your percentages in the blanks below, ensuring all percentages equal 100%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85670acd-6a39-4473-97c9-c1e8f3675e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDE THIS\n",
    "def create_percentage_widget():\n",
    "    # Create text widgets for percentages\n",
    "    training = widgets.BoundedIntText(\n",
    "        value=0,\n",
    "        min=0,\n",
    "        max=100,\n",
    "        description='Training %:',\n",
    "        layout=widgets.Layout(width='200px')\n",
    "    )\n",
    "\n",
    "    validation = widgets.BoundedIntText(\n",
    "        value=0,\n",
    "        min=0,\n",
    "        max=100,\n",
    "        description='Validation %:',\n",
    "        layout=widgets.Layout(width='200px')\n",
    "    )\n",
    "\n",
    "    testing = widgets.BoundedIntText(\n",
    "        value=0,\n",
    "        min=0,\n",
    "        max=100,\n",
    "        description='Testing %:',\n",
    "        layout=widgets.Layout(width='200px')\n",
    "    )\n",
    "\n",
    "    submit_button = widgets.Button(\n",
    "        description=\"Submit\"\n",
    "    )\n",
    "    \n",
    "    output = widgets.Output()\n",
    "    \n",
    "    def check_percentages(change=None):\n",
    "        with output:\n",
    "            output.clear_output()\n",
    "            total = training.value + validation.value + testing.value\n",
    "      \n",
    "            print(f\"Total: {total}%\")\n",
    "                \n",
    "    def on_submit_clicked(b):\n",
    "        with output:\n",
    "            output.clear_output()\n",
    "            check_percentages()  # Call without arguments\n",
    "            total = training.value + testing.value + validation.value\n",
    "            if total == 100:\n",
    "                print(\"â Submitted\")\n",
    "            else:\n",
    "                print(\"â ï¸ Make sure the percentages sum to 100% and resubmit.\")\n",
    "    \n",
    "    # Add observers\n",
    "    training.observe(check_percentages, names='value')\n",
    "    validation.observe(check_percentages, names='value')\n",
    "    testing.observe(check_percentages, names='value')\n",
    "    submit_button.on_click(on_submit_clicked)\n",
    "    \n",
    "    # Layout\n",
    "    widget_box = widgets.VBox([\n",
    "        widgets.HTML(value=\"<h3>Dataset Split Percentages</h3>\"),\n",
    "        training,\n",
    "        validation,\n",
    "        testing,\n",
    "        output,\n",
    "        submit_button\n",
    "    ])\n",
    "    \n",
    "    display(widget_box)\n",
    "    \n",
    "    # Return both the widget box and a function to get decimal values\n",
    "    def get_decimal_values():\n",
    "        return {\n",
    "            'training': training.value / 100,\n",
    "            'validation': validation.value / 100,\n",
    "            'testing': testing.value / 100\n",
    "        }\n",
    "    \n",
    "    return widget_box, get_decimal_values\n",
    "\n",
    "widget, get_values = create_percentage_widget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d1273d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDE THIS\n",
    "decimals = get_values()\n",
    "training = decimals['training']\n",
    "validation = decimals['validation']\n",
    "testing = decimals['testing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c11ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDE THIS\n",
    "def split_data_temporal(df, final_cutoff='2024-09-28', train_pct=0.6, val_pct=0.2, test_pct=0.2):\n",
    "    \"\"\"\n",
    "    Split data into training, validation, and testing sets based on chronological order.\n",
    "    The splits are created in this order: Training (earliest dates), Validation (middle dates),\n",
    "    Testing (latest dates before cutoff), and True Test (after cutoff)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas DataFrame\n",
    "        Input DataFrame with a 'date' column\n",
    "    final_cutoff : str\n",
    "        Date string for the cutoff between validation and true test sets\n",
    "    train_pct : float\n",
    "        Percentage of pre-cutoff data to use for training (default: 0.6)\n",
    "    val_pct : float\n",
    "        Percentage of pre-cutoff data to use for validation (default: 0.2)\n",
    "    test_pct : float\n",
    "        Percentage of pre-cutoff data to use for testing (default: 0.2)\n",
    "    \"\"\"\n",
    "    # Input validation\n",
    "    if not abs(train_pct + val_pct + test_pct - 1.0) < 1e-10:\n",
    "        raise ValueError(\"Training, validation, and testing percentages must sum to 1.0\")\n",
    "    \n",
    "    # Convert dates to pandas datetime\n",
    "    final_cutoff = pd.to_datetime(final_cutoff)\n",
    "    \n",
    "    # Create mask for true test set\n",
    "    true_test_mask = df['date'] > final_cutoff\n",
    "    \n",
    "    # Get the remaining data (everything up to final_cutoff)\n",
    "    remaining_data = df[~true_test_mask].copy()\n",
    "    remaining_data = remaining_data.sort_values('date')\n",
    "    \n",
    "    # Calculate the split points based on percentages\n",
    "    n_samples = len(remaining_data)\n",
    "    train_end_idx = int(n_samples * train_pct)\n",
    "    val_end_idx = int(n_samples * (train_pct + val_pct))  # Changed from test_end_idx\n",
    "    \n",
    "    # Get the dates at these split points\n",
    "    train_cutoff = remaining_data.iloc[train_end_idx]['date']\n",
    "    val_cutoff = remaining_data.iloc[val_end_idx]['date']  # Changed from test_cutoff\n",
    "    \n",
    "    # Create masks for each period in chronological order\n",
    "    train_mask = df['date'] <= train_cutoff\n",
    "    val_mask = (df['date'] > train_cutoff) & (df['date'] <= val_cutoff)  # Middle period\n",
    "    test_mask = (df['date'] > val_cutoff) & (df['date'] <= final_cutoff)  # Latest period before final cutoff\n",
    "    \n",
    "    # Split the data\n",
    "    # Exclude observation_datetime, year_index, and date from features\n",
    "    X_cols = [col for col in df.columns \n",
    "              if 'MITC' not in col \n",
    "              and col not in ['observation_datetime', 'year_index', 'date']]\n",
    "    y_cols = [col for col in df.columns if 'MITC' in col]\n",
    "    \n",
    "    # Create the splits in chronological order\n",
    "    X_train = df.loc[train_mask, X_cols]\n",
    "    y_train = df.loc[train_mask, y_cols]\n",
    "    \n",
    "    X_val = df.loc[val_mask, X_cols]\n",
    "    y_val = df.loc[val_mask, y_cols]\n",
    "    \n",
    "    X_test = df.loc[test_mask, X_cols]\n",
    "    y_test = df.loc[test_mask, y_cols]\n",
    "    \n",
    "    X_true_test = df.loc[true_test_mask, X_cols]\n",
    "    y_true_test = df.loc[true_test_mask, y_cols]\n",
    "    \n",
    "    # Print summary statistics in chronological order\n",
    "    print(\"Data split summary:\")\n",
    "    print(f\"Training period: {df.loc[train_mask, 'date'].min()} to {df.loc[train_mask, 'date'].max()}\")\n",
    "    print(f\"Training samples: {len(X_train)} ({len(X_train)/len(remaining_data):.1%} of pre-cutoff data)\")\n",
    "    \n",
    "    print(f\"\\nValidation period: {df.loc[val_mask, 'date'].min()} to {df.loc[val_mask, 'date'].max()}\")\n",
    "    print(f\"Validation samples: {len(X_val)} ({len(X_val)/len(remaining_data):.1%} of pre-cutoff data)\")\n",
    "    \n",
    "    print(f\"\\nTesting period: {df.loc[test_mask, 'date'].min()} to {df.loc[test_mask, 'date'].max()}\")\n",
    "    print(f\"Testing samples: {len(X_test)} ({len(X_test)/len(remaining_data):.1%} of pre-cutoff data)\")\n",
    "    \n",
    "    print(f\"\\nTrue test period: {df.loc[true_test_mask, 'date'].min()} to {df.loc[true_test_mask, 'date'].max()}\")\n",
    "    print(f\"True test samples: {len(X_true_test)}\")\n",
    "    \n",
    "    return (X_train, y_train, X_val, y_val, X_test, y_test, X_true_test, y_true_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4547defa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the function\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, X_true_test, y_true_test = split_data_temporal(df,\n",
    "                                                                                               train_pct=training,\n",
    "                                                                                               val_pct=validation,\n",
    "                                                                                               test_pct=testing)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b94e17c2-14c8-400e-9882-1016a33d888c",
   "metadata": {},
   "source": [
    "## Part 3: Model Development\n",
    "Next begins the iterative process of creating, evaluating, and refining your machine learning model. You will start with an initial model, and keep track of your subsequent trials in your Machine Learning Model Handbook. \n",
    "<center><a href=\"https://elearning.unidata.ucar.edu/dataeLearning/Cybertraining/analysis/media/RevisedFull_NOPROCESS_.png\" target=\"blank\"><img src=\"https://elearning.unidata.ucar.edu/dataeLearning/Cybertraining/analysis/media/RevisedFull_NOPROCESS_.png\"></a><br><i>Click to enlarge</i></center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc10b05e-e441-4af5-b7b5-e925294cf261",
   "metadata": {},
   "source": [
    "### Part 3a: Choose Algorithm\n",
    "First, you will choose an algorithm to train. You have two options: the *XGBR Regressor* and the *MultiLinearRegressor*. Both have pros and cons for this task. Choose one for your initial model, but you may choose to test the other algorithm in subsequent trials. \n",
    "\n",
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">About the Algorithms</p>\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">XGBR Regressor</p>\n",
    "    - Can make predictions on a variety of data distributions<br>\n",
    "    - Can overfit the data<br><br>\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">MultiLinearRegressor</p>\n",
    "    - Standard baseline linear model<br>\n",
    "    - Struggles to make predictions on non-uniformly distributed data\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee87acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def algorithm_selection():\n",
    "    \"\"\"Creates a widget and stores the selected algorithm.\"\"\"\n",
    "\n",
    "    algorithm_options = {\n",
    "        \"Multi-Linear Regressor\": \"linear_regression\",\n",
    "        \"XGBoost\": \"xgboost\"\n",
    "    }\n",
    "\n",
    "    buttons = [\n",
    "        widgets.Button(description=name, layout=widgets.Layout(width='200px', height='200px', margin='10px'))\n",
    "        for name in algorithm_options\n",
    "    ]\n",
    "\n",
    "    selected_algo = \"\" # Initialize as empty string.\n",
    "\n",
    "    def on_button_clicked(b):\n",
    "        global selected_algo # Access global variable\n",
    "        selected_algo = algorithm_options[b.description]\n",
    "        for button in buttons:\n",
    "            if button == b:\n",
    "                button.style.button_color = '#b2ebf2'\n",
    "            else:\n",
    "                button.style.button_color = None\n",
    "\n",
    "        print(f\"Selected Algorithm: {b.description}\")\n",
    "\n",
    "    for button in buttons:\n",
    "        button.on_click(on_button_clicked)\n",
    "\n",
    "    hbox = widgets.HBox(buttons)\n",
    "    display(hbox)\n",
    "\n",
    "    return selected_algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095e21a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_algo = algorithm_selection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b697844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDE THIS\n",
    "from xgboost import XGBRegressor\n",
    "import time \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.multioutput import MultiOutputRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b366c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDE THIS\n",
    "class MultiXGBRegressor(MultiOutputRegressor):\n",
    "    def __init__(self, estimator):\n",
    "        super().__init__(estimator)\n",
    "        self.estimators_ = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        start_time = time.time()\n",
    "        print(\"\\nStarting Multi-Target XGBoost Training Process...\")\n",
    "        y_np = y.values if hasattr(y, 'values') else np.array(y)\n",
    "        n_outputs = y_np.shape[1]\n",
    "        target_names = y.columns if hasattr(y, 'columns') else [f\"target_{i}\" for i in range(n_outputs)]\n",
    "        \n",
    "        self.estimators_ = [\n",
    "            XGBRegressor(**{k: v for k, v in self.estimator.get_params().items() \n",
    "                          if k != 'verbose'}) \n",
    "            for _ in range(n_outputs)\n",
    "        ]\n",
    "        \n",
    "        for i, (est, target) in enumerate(zip(self.estimators_, target_names)):\n",
    "            target_start = time.time()\n",
    "            print(f\"\\nTraining target {i+1}/{n_outputs}: {target}\", flush=True)\n",
    "            est.fit(X, y_np[:, i], verbose=False)\n",
    "            target_time = time.time() - target_start\n",
    "            print(f\"Target completed in {target_time:.2f} seconds\", flush=True)\n",
    "\n",
    "        total_time = time.time() - start_time\n",
    "        print(f\"\\nTotal training completed in {total_time:.2f} seconds\")\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023ffc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDE THIS\n",
    "class MultiLinearRegressor(MultiOutputRegressor):\n",
    "    def __init__(self):\n",
    "        super().__init__(LinearRegression())\n",
    "        self.estimators_ = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        start_time = time.time()\n",
    "        print(\"\\nStarting Multi-Target Linear Regression Training...\")\n",
    "        y_np = y.values if hasattr(y, 'values') else np.array(y)\n",
    "        n_outputs = y_np.shape[1]\n",
    "        target_names = y.columns if hasattr(y, 'columns') else [f\"target_{i}\" for i in range(n_outputs)]\n",
    "        \n",
    "        self.estimators_ = [LinearRegression() for _ in range(n_outputs)]\n",
    "        \n",
    "        for i, (est, target) in enumerate(zip(self.estimators_, target_names)):\n",
    "            target_start = time.time()\n",
    "            print(f\"\\nTraining target {i+1}/{n_outputs}: {target}\", flush=True)\n",
    "            est.fit(X, y_np[:, i])\n",
    "            target_time = time.time() - target_start\n",
    "            print(f\"Target completed in {target_time:.2f} seconds\", flush=True)\n",
    "\n",
    "        total_time = time.time() - start_time\n",
    "        print(f\"\\nTotal training completed in {total_time:.2f} seconds\")\n",
    "        return self"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "18b99dcf-1fa1-4e03-b826-492e5b71fb91",
   "metadata": {},
   "source": [
    "### Part 3b: Choose input features\n",
    "\n",
    "Given your data exploration, you must now choose the stations to use as input features. You may choose as many input stations as you'd like, however, recall that more stations does not always create a better model. Think strategically based on your evidence. \n",
    "\n",
    "<center><a href=\"https://elearning.unidata.ucar.edu/dataeLearning/Cybertraining/analysis/media/plotlystationmap.html\" target=\"blank\"><img src=\"https://elearning.unidata.ucar.edu/dataeLearning/Cybertraining/analysis/media/stationmap_plotly.png\"></a><br>\n",
    "<i>Click to open interactive map</i></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb47ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDE THIS\n",
    "def create_station_selector():\n",
    "    # List of all stations\n",
    "    stations = ['BURN', 'NCAT', 'SALI', 'SASS', 'FRYI', 'JEFF', 'BEAR', 'WINE', 'UNCA']\n",
    "    \n",
    "    # Create checkbox widgets for each station\n",
    "    checkboxes = {\n",
    "        station: widgets.Checkbox(\n",
    "            value=False,\n",
    "            description=station,\n",
    "            disabled=False,\n",
    "            indent=False\n",
    "        ) for station in stations\n",
    "    }\n",
    "    \n",
    "    # Create a container for all checkboxes\n",
    "    checkbox_grid = widgets.GridBox(\n",
    "        children=[checkboxes[station] for station in stations],\n",
    "        layout=widgets.Layout(\n",
    "            grid_template_columns='repeat(3, auto)',\n",
    "            grid_gap='10px'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Function to get selected stations\n",
    "    def get_selected_stations():\n",
    "        return [station for station, checkbox in checkboxes.items() if checkbox.value]\n",
    "    \n",
    "    # Create an output widget to display selected stations\n",
    "    output = widgets.Output()\n",
    "    \n",
    "    # Update function for when checkboxes change\n",
    "    def on_change(change):\n",
    "        with output:\n",
    "            output.clear_output()\n",
    "            selected = get_selected_stations()\n",
    "            print(f\"Selected stations: {', '.join(selected) if selected else 'None'}\")\n",
    "    \n",
    "    # Add observers to all checkboxes\n",
    "    for checkbox in checkboxes.values():\n",
    "        checkbox.observe(on_change, names='value')\n",
    "    \n",
    "    # Display everything\n",
    "    display(widgets.VBox([\n",
    "        widgets.HTML(value=\"<h3>Select Weather Stations</h3>\"),\n",
    "        checkbox_grid,\n",
    "        output\n",
    "    ]))\n",
    "    \n",
    "    return checkboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de3be7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_selector = create_station_selector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0c9b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can this be combined with the above? User gets feedback on \n",
    "# selected stations in the widget above, but will need for \n",
    "# the evaluation metrics in Validation and Testing\n",
    "\n",
    "# To get selected stations at any time:\n",
    "def get_selected_stations(selector):\n",
    "    return [station for station, checkbox in selector.items() if checkbox.value]\n",
    "\n",
    "selected = get_selected_stations(station_selector)\n",
    "selected "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3b76c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDE THIS\n",
    "def filter_dataframe(df, prefix_values):\n",
    "    \"\"\"\n",
    "    Filter DataFrame to keep only columns with specified prefixes plus day_index and hour_index.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): Input DataFrame\n",
    "    prefix_values (list): List of prefix values to match\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: Filtered DataFrame with only the specified columns\n",
    "    \"\"\"\n",
    "    # Print original column count\n",
    "    print(f\"Original DataFrame: {len(df.columns)} columns\")\n",
    "    \n",
    "    # Start with day_index and hour_index\n",
    "    columns_to_keep = ['day_index', 'hour_index']\n",
    "    \n",
    "    # Add any column that starts with our prefix values\n",
    "    for prefix in prefix_values:\n",
    "        matching_columns = [col for col in df.columns if col.startswith(prefix)]\n",
    "        columns_to_keep.extend(matching_columns)\n",
    "    \n",
    "    # Create filtered dataframe\n",
    "    filtered_df = df[columns_to_keep]\n",
    "    \n",
    "    # Print new column count\n",
    "    print(f\"Filtered DataFrame: {len(filtered_df.columns)} columns\")\n",
    "    \n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b094c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDE THIS - Or describe what's happening \n",
    "# (if keeping, need to eliminate or make the printout more understandable)\n",
    "X_train_filtered = filter_dataframe(X_train, selected)\n",
    "X_val_filtered = filter_dataframe(X_val, selected)\n",
    "X_test_filtered = filter_dataframe(X_test, selected)\n",
    "X_true_test_filtered = filter_dataframe(X_true_test, selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fbcd3e-bd91-4b20-9bb4-d354926e5472",
   "metadata": {},
   "source": [
    "### Part 3c: Train the Algorithm\n",
    "\n",
    "The training process is what transforms the machine learning algorithm you just selected into a supervised machine learning model. Executing the cell below starts the process of the agorithm learning patterns and relationships in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54adca6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_model = None  # Global variable for model access\n",
    "\n",
    "def create_model_button(selected_algo):  # selected_algo is now a parameter\n",
    "    \"\"\"Creates a single 'Train ML Model' button, using the provided selected_algo.\"\"\"\n",
    "    global selected_model\n",
    "    output = widgets.Output()\n",
    "\n",
    "    train_button = widgets.Button(description='Train Algorithm', layout=widgets.Layout(width='200px', height='200px'))\n",
    "\n",
    "    def train_model(b):\n",
    "        global selected_model\n",
    "        with output:\n",
    "            clear_output()\n",
    "            if selected_algo == \"xgboost\":\n",
    "                print(\"Running XGBoost model...\")\n",
    "                base_model = XGBRegressor(\n",
    "                    n_estimators=100,\n",
    "                    tree_method='hist',\n",
    "                    random_state=42\n",
    "                )\n",
    "                selected_model = MultiXGBRegressor(base_model) # Assuming this is defined\n",
    "                selected_model.fit(X_train_filtered, y_train) # Make sure these variables are available\n",
    "                print(\"XGBoost model training completed!\")\n",
    "            elif selected_algo == \"linear_regression\":\n",
    "                print(\"Running Linear Regression model...\")\n",
    "                selected_model = MultiLinearRegressor() # Assuming this is defined\n",
    "                selected_model.fit(X_train_filtered, y_train) # Make sure these variables are available\n",
    "                print(\"Linear Regression training completed!\")\n",
    "            else:\n",
    "                print(\"No algorithm selected. Cannot train.\")\n",
    "\n",
    "    train_button.on_click(train_model)\n",
    "\n",
    "    display(train_button)\n",
    "    display(output)\n",
    "\n",
    "    return selected_model  # Return the trained model (or None if not trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9e11f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_model_button(selected_algo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61c36ec-46d9-4d79-ade1-55bf639cabae",
   "metadata": {},
   "source": [
    "### Part 3c: Validate the Model\n",
    "\n",
    "The validation step uses validation data to evaluate how well the training process performed. By using a separate dataset to evaluate performance, we get a better sense of how well the model can generalize to new inputs.\n",
    "\n",
    "The cell below does several steps:\n",
    "1. Import the Python libraries that calculate statistics\n",
    "2. Make predictions with the validation dataset\n",
    "3. Generate validation metrics\n",
    "4. Print the validation metrics\n",
    "\n",
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">About the Evaluation Metrics</p>\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">Root Mean Square Error (RMSE)</p>\n",
    "    <ul>\n",
    "        <li>A measure of how large a typical prediction error is</li>\n",
    "        <li>Reports error in the original units (degrees, %, mph, etc)\n",
    "            <ul>\n",
    "                <li>e.g., an error of 5 mph means the prediction may be Â± 5 mph from the actual value</li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li>Better reflects the accuracy of predictions in real-world situations</li>\n",
    "        <li>Dependent on the scale of the dataset, making comparisons among datasets more difficult</li>\n",
    "    </ul>\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">RÂ²</p>\n",
    "    <ul>\n",
    "        <li>A measure of how well the model explains the variation in the dataset</li>\n",
    "        <li>A standardized scale (0-1) for comparing models across different trials</li>\n",
    "        <li>The closer to 1, the better the model accuracy</li>\n",
    "        <li>Assumes that the input data have a linear relationship</li>\n",
    "        <li>Only measures correlation among input data, cannot distinguish good and bad predictions</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45152ef-86bf-4fd8-a924-283605773a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the Python libraries that calculate \n",
    "# the evaluation metrics\n",
    "import numpy as np\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score\n",
    "\n",
    "# Make predictions (validation)\n",
    "y_pred = selected_model.predict(X_test_filtered)\n",
    "\n",
    "# Evaluate the model (generate validation metrics)\n",
    "rmse = root_mean_squared_error(y_test, y_pred, multioutput='raw_values')\n",
    "r2 = r2_score(y_test, y_pred, multioutput='raw_values')\n",
    "\n",
    "print(\"Validation Metrics\")\n",
    "print(\"\\nSelected Algorithm:\")\n",
    "print(selected_model)\n",
    "print(\"\\nSelected Stations:\")\n",
    "print(get_selected_stations(station_selector))\n",
    "print(\"\\nRMSE for each target feature:\")\n",
    "for target, error in zip(y_test.columns, rmse):\n",
    "    print(f\" {target}:\\t{error:.4f}\")\n",
    "\n",
    "print(\"\\nRÂ² Score for each target feature:\")\n",
    "for target, score in zip(y_test.columns, r2):\n",
    "    print(f\" {target}:\\t{score:.4f}\")\n",
    "\n",
    "# Overall performance\n",
    "print(f\" Average RÂ² Score:\\t{np.mean(r2):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f3e964-4f0a-44d5-baa1-65b9c9a4d169",
   "metadata": {},
   "source": [
    "### Part 3d: Evaluate and Refine the Model\n",
    "\n",
    "Examine the results of the model validation. What do each mean? Could they be improved? Review the descriptions of the evaluation metrics, then complete the next exercise. \n",
    "\n",
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "<p class=\"admonition-title\" style=\"font-weight:bold\">Exercise 3d</p>\n",
    "    <p>In your <b>Machine Learning Model Handbook</b>, describe the results of your initial model validation.</p>\n",
    "        <p>Paste your evaluation metrics in the designated box. </p>\n",
    "        <p>Describe the results of your initial model validation. Include the following:</p>\n",
    "    <ul>\n",
    "        <li>How do you interpret these results in the context of the real-world situation?</li>\n",
    "        <li>Potentially how could these metrics be improved in your next iteration? Why?</li>\n",
    "    </ul>\n",
    "    </p>\n",
    "    <p>GENERAL RUBRIC TBD</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4c6653-d035-4415-b953-962328ce1e73",
   "metadata": {},
   "source": [
    "### Part 3e: Iterative Refinement Trials\n",
    "\n",
    "Your first trial is complete! Now you'll create new trials to improve the evaluation metrics from the validation phase. Here's how:\n",
    "\n",
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "<p class=\"admonition-title\" style=\"font-weight:bold\">Exercise 3e</p>\n",
    "    <ol>\n",
    "        <li>Return to <a href =\"#Part-3a:-Choose-Algorithm\">Part 3a: Choose Algorithm</a> and choose to either change or keep your algorithm</li>\n",
    "        <li>Proceed to Part 3b to choose new stations, or keep the stations you already have</li>\n",
    "        <li>Re-train your model</li>\n",
    "        <li>Re-validate your model and review the evaluation metrics</li>\n",
    "        <li>Paste the results of each trial in your Machine Learning Model Handbook</li>\n",
    "        <li>Repeat this process until you have metrics you are satisfied with, and move on to the next part below</li>\n",
    "    </ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37323e1-2a75-4f9b-9071-a3e79cd78dd5",
   "metadata": {},
   "source": [
    "### Part 3f: Test Model\n",
    "\n",
    "<div class=\"alert alert-warning\" role=\"alert\">\n",
    "<p class=\"admonition-title\" style=\"font-weight:bold\">Important</p>\n",
    "    For testing, your model needs to be in a state with your desired algorithm and input feature stations. If you haven't already, go back and run through parts 3a through 3c with your final choices one last time. This ensures that your final testing process will be executed with your desired choices. \n",
    "</div>\n",
    "\n",
    "At this point, you have a trained and validated model with evaluation metrics you are satisfied with. Next, it's time to test the model on brand new data, the testing dataset. The testing process mimics how the model would be used in a real-world process in a final, unbiased way. \n",
    "\n",
    "Testing looks very similar to validation. The model makes predictions based on the input features in the testing dataset, then RMSE and RÂ² are calculated. Execute the cell below to test the model and view the testing metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3402ef-da3f-45c0-b4bf-7a89293b5c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = selected_model.predict(X_val_filtered)\n",
    "\n",
    "# Evaluate the model\n",
    "rmse = root_mean_squared_error(y_val, y_pred, multioutput='raw_values')\n",
    "r2 = r2_score(y_val, y_pred, multioutput='raw_values')\n",
    "\n",
    "# Print metrics\n",
    "print(\"Testing Metrics\")\n",
    "print(\"\\nSelected Algorithm:\")\n",
    "print(selected_model)\n",
    "print(\"\\nSelected Stations:\")\n",
    "print(get_selected_stations(station_selector))\n",
    "\n",
    "print(\"\\nRMSE for each target feature:\")\n",
    "for target, error in zip(y_val.columns, rmse):\n",
    "    print(f\" {target}:\\t{error:.4f}\")\n",
    "print(\"\\nRÂ² Score for each target feature:\")\n",
    "for target, score in zip(y_val.columns, r2):\n",
    "    print(f\" {target}:\\t{score:.4f}\")\n",
    "\n",
    "# Overall performance\n",
    "print(f\" Average RÂ² Score:\\t{np.mean(r2):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e20b35-3933-457a-b454-925143761974",
   "metadata": {},
   "source": [
    "### Part 3g: Evaluate and Justify\n",
    "\n",
    "With your model trained, validated, and tested, you can now plot the predicted model output alongside the real data before the Mt. Mitchell station went offline. You can use this information to help you address your final model justification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6794c10-c2be-4aba-84c4-e98531ed8390",
   "metadata": {},
   "outputs": [],
   "source": [
    "### I want this plot to have this formatting\n",
    "### x5, vertically stacked subplots\n",
    "### Only showing obs @ MITC from 2024\n",
    "### Real data shown as #77aadd\n",
    "### Predictions shown as #ee8866\n",
    "\"\"\"\n",
    "xdates = pd.to_datetime(df['observation_datetime'])\n",
    "fig, ax = plt.subplots(1, 1, tight_layout=True)\n",
    "ax.plot(xdates[::100], df[selected_var][::100], label=var_dropdown.label, color='orange')\n",
    "ax.set_title(f\"Time Series of {var_dropdown.label} at {station_dropdown.value}\", fontsize=14)\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_ylabel(var_dropdown.label)\n",
    "ax.xaxis.set_major_locator(mdates.YearLocator())\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "plt.show()\n",
    "\"\"\"\n",
    "\n",
    "y_pred = selected_model.predict(X_true_test_filtered)\n",
    "\n",
    "fig, axs = plt.subplots(5, 1, figsize=(15, 10), sharex=True)\n",
    "labels = ['Air Temperature (Â°F)', 'Wind Speed (mph)', 'Wind Gust (mph)', 'RH (%)', 'Precipitation (in)']\n",
    "for i, (ax, label) in enumerate(zip(axs, labels)):\n",
    "    ax.plot(y_pred[:, i])\n",
    "    ax.set_ylabel(label)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "axs[-1].set_xlabel('Hours')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d4f576-7b33-4eb8-a958-0470baf0565b",
   "metadata": {},
   "source": [
    "#### Your final decision\n",
    "\n",
    "Given all your evaluation, it's time to make a final decision on whether you believe this model provides sufficient skill for the task at hand. Go back and review your problem statement. Does this model deliver the results needed?\n",
    "\n",
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "<p class=\"admonition-title\" style=\"font-weight:bold\">Exercise 3g</p>\n",
    "    <p>In your <b>Machine Learning Model Handbook</b>, make a final decision on whether this model delivers on the results needed with supporting justification. Include the following:\n",
    "    <ul>\n",
    "        <li>Which environmental variables had the best evaluation metrics? List some physical scientific reasons why this may be the case.</li>\n",
    "        <li>Is this model ready for use in the real world? Why or Why not?</li>\n",
    "        <li>What other possible changes could further improve this model?</li>\n",
    "    </ul>\n",
    "    </p>\n",
    "    <p>GENERAL RUBRIC TBD</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85094e6-95f7-4c12-a8a2-7d3f20c8f3d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
