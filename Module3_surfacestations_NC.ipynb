{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9805bfd2-b31d-4b2f-b325-a409c27f96c7",
   "metadata": {},
   "source": [
    "<img src=\"https://elearning.unidata.ucar.edu/dataeLearning/Cybertraining/analysis/media/NSF-Unidata_lockup_vertical_2023.png\" width=\"150px\" align=\"right\">\n",
    "\n",
    "# Machine Learning Analysis in the Earth Systems Sciences\n",
    "\n",
    "In this module, you are tasked with planning, implementing, and evaluating a machine learning solution for a real-world scenario. Given pre-configured code blocks and prepared data, you will create a problem statement, explore the data, experiment with model development, and ultimately make a recommendation on the utility of machine learning for your scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e3747f-a6cf-4326-9e5c-67117de117b9",
   "metadata": {},
   "source": [
    "# Damaged weather station in western North Carolina\n",
    "\n",
    "Play the video below to learn about the situation.\n",
    "\n",
    "<video width=\"600\" controls><source src=\"https://elearning.unidata.ucar.edu/dataeLearning/Cybertraining/analysis/media/stationsintrovideo_i1_nojupyterdemo.mp4\" type=\"video/mp4\">\n",
    "</video>\n",
    "\n",
    "<a href=\"https://www.google.com/url?q=https://docs.google.com/document/d/e/2PACX-1vRfYtUFjLVfNadQ0nvUv4E8MzfaXmQwt_WcP0haCo5bH1J0zGZiupiJz7XuLsun2BqN-g_ubbACpx6p/pub&sa=D&source=docs&ust=1738596555923034&usg=AOvVaw2xJ1FEg1SflwC6i3P5uQqD\" target=\"blank\">Transcript</a>\n",
    "\n",
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "<p class=\"admonition-title\" style=\"font-weight:bold\">What is a data engineer?</p>\n",
    "    <p>Your team includes yourself, your team lead, and a data engineer. Data engineering is an emerging career that encompasses the collection, storage, and pre-processing of data in data science disciplines. You will see the type of work that the data engineer on your team does in <i>Part 2: Data Handling.</i></p>\n",
    "    <p><a href=\"https://www.mongodb.com/resources/basics/data-engineering#what-is-data-engineering\" target=\"blank\">Learn more</a></p>\n",
    "</div>\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5cad94-efb5-4291-830e-64a8ad7ea483",
   "metadata": {},
   "source": [
    "Now you will begin the process of following the supervised machine learning model framework to address this task, starting with <b>problem framing</b>.\n",
    "<center><a href=\"https://elearning.unidata.ucar.edu/dataeLearning/Cybertraining/analysis/media/RevisedFull_NOPROCESS_.png\" target=\"blank\"><img src=\"https://elearning.unidata.ucar.edu/dataeLearning/Cybertraining/analysis/media/RevisedFull_NOPROCESS_.png\"></a><br><i>Click to enlarge</i></center>\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8ffff5-7731-4142-bd98-d9f5db95dd13",
   "metadata": {},
   "source": [
    "## Part 1: Problem Framing\n",
    "\n",
    "Based on the information provided in the video, which type of machine learning analysis is most appropriate for this scenario? \n",
    "\n",
    "> **Instructions**\n",
    "> \n",
    "> Execute the two cells below. After executing `display_quiz()`, select the corresponding button to check your understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bee4cd7-65d4-47b5-b461-48d17890a0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First import the Python tools needed to display the buttons\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output, HTML, IFrame\n",
    "\n",
    "from button_tech import display_quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8d6ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_quiz()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df781998-2df2-46ab-9cac-68a65930dd9c",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c41fcf-e3c0-488e-9c71-de6c5d088b12",
   "metadata": {},
   "source": [
    "#### Problem framing questions\n",
    "As a part of the problem framing step, we must answer a series of questions to ensure we're creating the best solution for this scenario. \n",
    "\n",
    "***Does a simpler solution exist?***\n",
    "\n",
    "&emsp;From the video, we know that your team has already completed a preliminary analysis that averaged values from nearby stations to Mt Mitchell. While these results showed some skill, there is room for improvement. \n",
    "\n",
    "***Can machine learning requirements be met?***\n",
    "\n",
    "&emsp;The NC ECONet data provider has decades of hourly data available from several weather stations. This is sufficient for your model. \n",
    "\n",
    "***Which scientific question should be answered?***\n",
    "\n",
    "&emsp;You will answer this question in **Exercise 1** below. \n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd95337-12f5-4e9b-a786-979ebad08b20",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "<p class=\"admonition-title\" style=\"font-weight:bold\">Exercise 1</p>\n",
    "    <p>Open your <b>Machine Learning Model Handbook</b> to Exercise 1. Then type the scientific question to be answered for this situation.</p>\n",
    "</div>\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40af46bf-61eb-4cdd-8701-aa774ffce5af",
   "metadata": {},
   "source": [
    "## Part 2: Data Handling\n",
    "\n",
    "<center><a href=\"https://elearning.unidata.ucar.edu/dataeLearning/Cybertraining/analysis/media/RevisedFull_NOPROCESS_.png\" target=\"blank\"><img src=\"https://elearning.unidata.ucar.edu/dataeLearning/Cybertraining/analysis/media/RevisedFull_NOPROCESS_.png\"></a><br><i>Click to enlarge</i></center>\n",
    "<br><br>\n",
    "\n",
    "Recall that data preparation is often the most time-consuming step of developing a machine learning model. Data handling comes in three parts:\n",
    "1. Locate data of interest\n",
    "2. Explore data\n",
    "3. Create a data splitting strategy\n",
    "\n",
    "Your team's data engineer has located the data and completed the pre-processing for you already, and you will follow with your own independent exploration of the data and strategy for data splitting. \n",
    "\n",
    "<br>\n",
    "\n",
    "### Part 2a: Locate Data of Interest\n",
    "\n",
    "You will be using other stations in the <a href=\"https://econet.climate.ncsu.edu/\" target=\"blank\">NC ECONet</a> for this project. Below is a document that your team's data engineer has prepared for you describing the nature of the dataset that will be used to create the machine learning model. <br><br>\n",
    "\n",
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "### Metadata Document for Western North Carolina Weather Station Data\n",
    "\n",
    "#### General Information\n",
    "\n",
    "Dataset Name: Western NC Weather Station Time-Series Data\n",
    "\n",
    "Description: This dataset contains tabular time-series data collected from multiple weather stations in Western North Carolina. The data includes atmospheric and environmental variables recorded at hourly intervals.\n",
    "\n",
    "Date Range: January 1, 2015, to December 16, 2024\n",
    "\n",
    "Geographic Coverage: Western North Carolina \n",
    "\n",
    "Data Frequency: Hourly\n",
    "\n",
    "Last Updated: Jan 1, 2025\n",
    "\n",
    "#### Data Structure\n",
    "\n",
    "File Format: .parquet\n",
    "\n",
    "Number of Records: 69,760 per station per feature\n",
    "\n",
    "Columns (Features) \n",
    "\n",
    "- observation_datetime: Date and time of observation in UTC\n",
    "\n",
    "Columns (features) per Station (XXXX):\n",
    "\n",
    "- XXXX_airtemp_degF (Â°F): Air temperature measured at 2 meters above ground level\n",
    "- XXXX_windspeed_mph (mph): Average wind speed during the hour at 10 meters above ground level\n",
    "- XXXX_winddgust_mph (mph): Peak wind gust during the hour at 10 meters above ground level\n",
    "- XXXX_rh_percent (%): Average Relative humidity\n",
    "- XXXX_precip_in (in): Total precipitation accumulated in the hour\n",
    "\n",
    "Stations:\n",
    "\n",
    "- BEAR (Bearwallow Mountain)\n",
    "- BURN (Burnsville Tower)\n",
    "- FRYI (Frying Pan Mountain)\n",
    "- JEFF (Mount Jefferson Tower)\n",
    "- **MITC (Mount Mitchell State Park) - target station**\n",
    "- NCAT (North Carolina A&T University Research Farm)\n",
    "- SALI (Piedmont Research Station)\n",
    "- SASS (Sassafrass Mountain)\n",
    "- UNCA (University of North Carolina - Asheville Weather Tower)\n",
    "- WINE (Wayah Bald Mountain)\n",
    "\n",
    "<a href=\"https://econet.climate.ncsu.edu/\" target=\"blank\">More station info</a>\n",
    "\n",
    "#### Data Quality\n",
    "\n",
    "Missing Data: Missing data besides MITC was filled in using seasonal values and basic interpolation.\n",
    "\n",
    "Outlier Handling: No outlier handling was done. \n",
    "\n",
    "#### Data Provenance\n",
    "\n",
    "Source: North Carolina State Climate Office ECONet, <a href=\"https://econet.climate.ncsu.edu\" target=\"blank\">https://econet.climate.ncsu.edu/about/</a>\n",
    "\n",
    "</div>\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ce9319-3e5c-4632-a488-b777f93c9603",
   "metadata": {},
   "source": [
    "### Part 2b: Explore Data\n",
    "\n",
    "While your data engineer colleague prepared the data for your model and created the metadata document, you will still need to familiarize yourself with the data before you use it as input to a machine learning algorithm. In this step, you will take a closer look at the potential features for your model with a few plots. \n",
    "\n",
    "First, let's read the data into this workspace. The data resides on a remote THREDDS Data Server, which allows users to access data without manually downloading files to your computer. When you execute the code cell below, you will load the Python library `pandas` that includes all the tools for reading the data from the THREDDS Data Server and opening it in this workspace. \n",
    "\n",
    "> **Instructions**\n",
    "> \n",
    "> Execute the  cell below\n",
    "> \n",
    "> *This may take a moment to complete.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d6c37c-c245-4006-9e15-2c3674b17da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pandas Python library that can interpret the data file\n",
    "import pandas as pd\n",
    "\n",
    "# Location of the data on the THREDDS data server\n",
    "file_path = 'https://thredds.ucar.edu/thredds/fileServer/cybertraining/CyberTraining_NC_ECOnet_data.parquet'\n",
    "\n",
    "# Read data into this workspace\n",
    "df = pd.read_parquet(file_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4557a370-47ac-4762-ab41-b3dabb6e678c",
   "metadata": {},
   "source": [
    "The ***target features*** (the features that we are trying to predict with the machine learning model) are temperature, relative humidity, wind speed, wind gust, and precipitation at the Mt. Mitchell station. All other station data are possible ***input features*** to the model. \n",
    "\n",
    "#### Explore target features\n",
    "\n",
    "Let's now explore just the target features at Mt. Mitchell.  \n",
    "\n",
    "\n",
    "> **Instructions**\n",
    "> \n",
    "> Execute the two cells below.\n",
    "> \n",
    "> In the Mt. Mitchell plotting widget, select the environmental variable and plot type from the dropdowns, then select Plot to reveal the plot.\n",
    ">\n",
    "> Repeat for any and all variales you want to explore to better understand the data at Mt. Mitchell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb05b604",
   "metadata": {},
   "outputs": [],
   "source": [
    "from button_tech import display_mt_mitchell_weather_dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9581a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_mt_mitchell_weather_dashboard(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ba0556d7-3f62-486a-8940-85395948e0be",
   "metadata": {},
   "source": [
    "#### Explore input features\n",
    "\n",
    "Now explore the ***input features***. Below is a map of where the stations are located in relation to MITC. Click on the image below to open an interactive map.\n",
    "\n",
    "<center><a href=\"https://elearning.unidata.ucar.edu/dataeLearning/Cybertraining/analysis/media/plotlystationmap.html\" target=\"blank\"><img src=\"https://elearning.unidata.ucar.edu/dataeLearning/Cybertraining/analysis/media/stationmap_plotly.png\"></a><br>\n",
    "<i>Click to open interactive map</i></center>\n",
    "\n",
    "> **Instructions**\n",
    "> \n",
    "> Execute the two cells below.\n",
    ">\n",
    "> In the Input Stations plotting widget, select the station, environmental variable, and plot type from the dropdowns. Then select Plot to reveal the plot.\n",
    ">\n",
    "> Repeat for any and all variables you want to explore to better understand the data at each station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68121f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from button_tech import display_input_stations_dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81b0e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_input_stations_dashboard(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c12f3e",
   "metadata": {},
   "source": [
    "#### Compare stations\n",
    "We can also plot direct comparisons of stations in our dataset by plotting data at each station in a grid of plots. In these comparison grids, the scatter plots display the observations at each station, for example, the temperature at MITC on the x-axis and the temperature at SASS on the y-axis. Stations that are well-correlated will show points that are generally clustered with very little spread. \n",
    "\n",
    "<center><a href=\"https://elearning.unidata.ucar.edu/dataeLearning/Cybertraining/analysis/media/wellcorrelated.png\" target=\"blank\"><img src=\"https://elearning.unidata.ucar.edu/dataeLearning/Cybertraining/analysis/media/wellcorrelated.png\" width=\"200 px\"></a> <a href=\"https://elearning.unidata.ucar.edu/dataeLearning/Cybertraining/analysis/media/notwellcorrelated.png\" target=\"blank\"><img src=\"https://elearning.unidata.ucar.edu/dataeLearning/Cybertraining/analysis/media/notwellcorrelated.png\" width=\"200 px\"></a><br><i>Click to enlarge</i></center>\n",
    "\n",
    "The grid displays histograms where the x- and y-axes are the same station. These are the same histograms that you plotted previously, displaying the distribution of all values at that station. \n",
    "\n",
    "> **Instructions**\n",
    "> \n",
    "> Execute the two cells below.\n",
    ">\n",
    "> In the Comparison Plot plotting widget, select an environmental variable from the dropdown, then select Plot to reveal the plot.\n",
    "> \n",
    "> Repeat for any and all variables you want to explore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c922a5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from button_tech import display_correlation_plot_dashboard\n",
    "display(HTML(\"<h3>Comparison Plot</h3>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63663049",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_correlation_plot_dashboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49eb31c-c0cf-477d-a771-282d49442189",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "<p class=\"admonition-title\" style=\"font-weight:bold\">Exercise 2b</p>\n",
    "    <p>Open your <b>Machine Learning Model Handbook</b> to Exercise 2b. Then describe your exploratory data analysis of any target and input features of note. Include the following:\n",
    "    <ul>\n",
    "        <li>Do variables follow diurnal or annual patterns generally as expected?</li>\n",
    "        <li>Do the variables have the expected ranges of values? Do any variables appear to include major outliers?</li>\n",
    "        <li>Which stations appear to be most correlated to the variables at Mt Mitchell? Why?</li>\n",
    "        <li>Include any <i>important</i> plots to illustrate your conclusions. Limit yourself to 5 plots. <br><i>To copy a plot image, hold shift, right click on the image, then select Copy.</i></li>\n",
    "    </ul>\n",
    "    </p>\n",
    "</div>\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2179f158-8f6b-45f3-ab00-aa889b092160",
   "metadata": {},
   "source": [
    "### Part 2c: Create a data splitting strategy\n",
    "\n",
    "Next we create a data splitting strategy. Data splitting refers to the process of dividing data into three groups: training, validation, and testing. Each of these groups represent a part of the iterative process for machine learning model development. \n",
    "\n",
    "- Training data is the largest subset, usually around 60-80% of the total data, and is used to initially train the model. \n",
    "- Validation data is roughly 10-20% of the total data, and is used to validate the effectiveness of the training process. \n",
    "- Testing data is also roughly 10-20% of the total data, and is used to test the final refined model before using it on new, unseen data.\n",
    "\n",
    "Each group should be separate to ensure no single group will bias the model. In this model, the data will be randomly split into these groups, but you decide the proportions of data for each group. Input your percentages in the blanks below, ensuring all percentages equal 100%.\n",
    "\n",
    "> **Instructions**\n",
    "> \n",
    "> Execute the two cells below.\n",
    ">\n",
    "> In the Dataset Split Percentages widget, select the proportions of the total dataset you wish to use in each group by typing in each box. Use values 0-100, ensuring that the sum of all three boxes equals 100.\n",
    ">\n",
    "> Select Submit after making your selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386cc8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from button_tech import create_percentage_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0d113b",
   "metadata": {},
   "outputs": [],
   "source": [
    "widget, get_values = create_percentage_widget()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7aa6420-48c4-44d5-a6a2-3a9fa6c32db8",
   "metadata": {},
   "source": [
    "> **Instructions**\n",
    "> \n",
    "> Execute the three cells below to execute the functions to split the data according to the percentages you submitted above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d1273d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is used to grab the values from the widget above (no need to change)\n",
    "decimals = get_values()\n",
    "training = decimals['training']\n",
    "validation = decimals['validation']\n",
    "testing = decimals['testing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c11ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "from button_tech import split_data_temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4547defa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the function\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, X_true_test, y_true_test = split_data_temporal(df,\n",
    "                                                                                               train_pct=training,\n",
    "                                                                                               val_pct=validation,\n",
    "                                                                                               test_pct=testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65413753-d13c-4a79-9127-fa507f7d25a5",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b94e17c2-14c8-400e-9882-1016a33d888c",
   "metadata": {},
   "source": [
    "## Part 3: Model Development\n",
    "Next begins the iterative process of creating, evaluating, and refining your machine learning model. You will start with an initial model, and keep track of your subsequent trials in your Machine Learning Model Handbook. \n",
    "<center><a href=\"https://elearning.unidata.ucar.edu/dataeLearning/Cybertraining/analysis/media/RevisedFull_NOPROCESS_.png\" target=\"blank\"><img src=\"https://elearning.unidata.ucar.edu/dataeLearning/Cybertraining/analysis/media/RevisedFull_NOPROCESS_.png\"></a><br><i>Click to enlarge</i></center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc10b05e-e441-4af5-b7b5-e925294cf261",
   "metadata": {},
   "source": [
    "### Part 3a: Choose Algorithm\n",
    "First, you will choose an algorithm to train. You have two options: the *XGBR Regressor* and the *MultiLinearRegressor*. Both have pros and cons for this task. Choose one for your initial model, but you may choose to test the other algorithm in subsequent trials. \n",
    "\n",
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">About the Algorithms</p>\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">XGBR Regressor</p>\n",
    "    <ul>\n",
    "        <li>Handles a Wide Range of Data Distributions: XGBR is capable of modeling both linear and non-linear relationships, making it suitable for data with complex, varied distributions.</li>\n",
    "        <li>Prone to Overfitting: XGBR can easily overfit to training data, especially when the dataset is small or noisy.</li>\n",
    "    </ul>\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">MultiLinearRegressor</p>\n",
    "    <ul>\n",
    "        <li>Simple and Interpretable: As a linear model, it is easy to understand and interpret, making it a great choice for those seeking clear relationships between features and predictions.</li>\n",
    "        <li>Struggles with Non-Uniform Data Distributions: For datasets with non-linear patterns or skewed distributions, multiple linear regression may fail to capture the underlying patterns, leading to biased or inaccurate predictions.</li>\n",
    "</div>\n",
    "\n",
    "> **Instructions**\n",
    "> \n",
    "> Execute the two cells below.\n",
    ">\n",
    "> After executing `algorithm_selection()`, select the corresponding button to select your desired algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14e8307",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "import time \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from button_tech import algorithm_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095e21a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_algo = algorithm_selection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389ba785",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_algo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d584d7f-c94a-4eaa-8c51-404791cfc390",
   "metadata": {},
   "source": [
    "## @ TM: Is this cell ^ needed for the code that follows? Unsure how to describe what it's doing, or if it could be consolidated with the cells above "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe69240a-02f9-435f-9b29-7452df8164d2",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "18b99dcf-1fa1-4e03-b826-492e5b71fb91",
   "metadata": {},
   "source": [
    "### Part 3b: Choose input features\n",
    "\n",
    "Given your data exploration, you must now choose the stations to use as input features. You may choose as many input stations as you'd like, however, recall that more stations does not always create a better model. Think strategically based on your evidence. \n",
    "\n",
    "<center><a href=\"https://elearning.unidata.ucar.edu/dataeLearning/Cybertraining/analysis/media/plotlystationmap.html\" target=\"blank\"><img src=\"https://elearning.unidata.ucar.edu/dataeLearning/Cybertraining/analysis/media/stationmap_plotly.png\"></a><br>\n",
    "<i>Click to open interactive map</i></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9edb193",
   "metadata": {},
   "outputs": [],
   "source": [
    "from button_tech import create_station_selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de3be7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_selector = create_station_selector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0c9b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can this be combined with the above? User gets feedback on \n",
    "# selected stations in the widget above, but will need for \n",
    "# the evaluation metrics in Validation and Testing\n",
    "\n",
    "# To get selected stations at any time:\n",
    "def get_selected_stations(selector):\n",
    "    return [station for station, checkbox in selector.items() if checkbox.value]\n",
    "\n",
    "selected = get_selected_stations(station_selector)\n",
    "selected "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de1e99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from button_tech import filter_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b094c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDE THIS - Or describe what's happening \n",
    "# (if keeping, need to eliminate or make the printout more understandable)\n",
    "X_train_filtered = filter_dataframe(X_train, selected)\n",
    "X_val_filtered = filter_dataframe(X_val, selected)\n",
    "X_test_filtered = filter_dataframe(X_test, selected)\n",
    "X_true_test_filtered = filter_dataframe(X_true_test, selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fbcd3e-bd91-4b20-9bb4-d354926e5472",
   "metadata": {},
   "source": [
    "### Part 3c: Train the Algorithm\n",
    "\n",
    "The training process is what transforms the machine learning algorithm you just selected into a supervised machine learning model. Executing the cell below starts the process of the agorithm learning patterns and relationships in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a388a0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from button_tech import train_model_button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9e11f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If having issues with this cell, re-run it usually fixes it\n",
    "\n",
    "model_choice = selected_algo()\n",
    "trained_model = train_model_button(model_choice, X_train_filtered, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61c36ec-46d9-4d79-ade1-55bf639cabae",
   "metadata": {},
   "source": [
    "### Part 3c: Validate the Model\n",
    "\n",
    "The validation step uses validation data to evaluate how well the training process performed. By using a separate dataset to evaluate performance, we get a better sense of how well the model can generalize to new inputs.\n",
    "\n",
    "The cell below does several steps:\n",
    "1. Import the Python libraries that calculate statistics\n",
    "2. Make predictions with the validation dataset\n",
    "3. Generate validation metrics\n",
    "4. Print the validation metrics\n",
    "\n",
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">About the Evaluation Metrics</p>\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">Root Mean Square Error (RMSE)</p>\n",
    "    <ul>\n",
    "        <li>A measure of how large a typical prediction error is</li>\n",
    "        <li>Reports error in the original units (degrees, %, mph, etc)\n",
    "            <ul>\n",
    "                <li>e.g., an error of 5 mph means the prediction may be Â± 5 mph from the actual value</li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li>Better reflects the accuracy of predictions in real-world situations</li>\n",
    "        <li>Dependent on the scale of the dataset, making comparisons among datasets more difficult</li>\n",
    "    </ul>\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">RÂ²</p>\n",
    "    <ul>\n",
    "        <li>A measure of how well the model explains the variation in the dataset</li>\n",
    "        <li>A standardized scale (0-1) for comparing models across different trials</li>\n",
    "        <li>The closer to 1, the better the model accuracy</li>\n",
    "        <li>Assumes that the input data have a linear relationship</li>\n",
    "        <li>Only measures correlation among input data, cannot distinguish good and bad predictions</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66842084",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score\n",
    "\n",
    "from button_tech import model_eval_MITC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0ff68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eval_MITC(trained_model(), X_test_filtered, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f3e964-4f0a-44d5-baa1-65b9c9a4d169",
   "metadata": {},
   "source": [
    "### Part 3d: Evaluate and Refine the Model\n",
    "\n",
    "Examine the results of the model validation. What do each mean? Could they be improved? Review the descriptions of the evaluation metrics, then complete the next exercise. \n",
    "\n",
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "<p class=\"admonition-title\" style=\"font-weight:bold\">Exercise 3d</p>\n",
    "    <p>Open your <b>Machine Learning Model Handbook</b> to Exercise 3d. </p>\n",
    "    <p>Paste your evaluation metrics in the designated box. </p>\n",
    "    <p>Then describe the results of your initial model validation. Include the following:</p>\n",
    "    <ul>\n",
    "        <li>Which variables have favorable evaluation metrics? Which variables donât perform as well?</li>\n",
    "        <li>How do you interpret these results in the context of the real-world situation?</li>\n",
    "        <li>What changes will you make to try to improve these statistics in the next iteration?</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4c6653-d035-4415-b953-962328ce1e73",
   "metadata": {},
   "source": [
    "### Part 3e: Iterative Refinement Trials\n",
    "\n",
    "Your first trial is complete! Now you'll create new trials to improve the evaluation metrics from the validation phase. Here's how:\n",
    "\n",
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "<p class=\"admonition-title\" style=\"font-weight:bold\">Exercise 3e</p>\n",
    "    <ol>\n",
    "        <li>Return to <a href =\"#Part-3a:-Choose-Algorithm\">Part 3a: Choose Algorithm</a> and choose to either change or keep your algorithm</li>\n",
    "        <li>Proceed to Part 3b to choose new stations, or keep the stations you already have</li>\n",
    "        <li>Re-train your model</li>\n",
    "        <li>Re-validate your model and review the evaluation metrics</li>\n",
    "        <li><b>In your Machine Learning Model Handbook Exercise 3e,</b> paste the results of each trial, one per box.</li>\n",
    "        <li>Repeat this process until you have metrics you are satisfied with, and move on to the next part below</li>\n",
    "    </ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37323e1-2a75-4f9b-9071-a3e79cd78dd5",
   "metadata": {},
   "source": [
    "### Part 3f: Test Model\n",
    "\n",
    "<div class=\"alert alert-warning\" role=\"alert\">\n",
    "<p class=\"admonition-title\" style=\"font-weight:bold\">Important</p>\n",
    "    For testing, your model needs to be in a state with your desired algorithm and input feature stations. If you haven't already, go back and run through parts 3a through 3c with your final choices one last time. This ensures that your final testing process will be executed with your desired choices. \n",
    "</div>\n",
    "\n",
    "At this point, you have a trained and validated model with evaluation metrics you are satisfied with. Next, it's time to test the model on brand new data, the testing dataset. The testing process mimics how the model would be used in a real-world process in a final, unbiased way. \n",
    "\n",
    "Testing looks very similar to validation. The model makes predictions based on the input features in the testing dataset, then RMSE and RÂ² are calculated. Execute the cell below to test the model and view the testing metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c4350a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eval_MITC(trained_model(), X_val_filtered, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e20b35-3933-457a-b454-925143761974",
   "metadata": {},
   "source": [
    "### Part 3g: Evaluate and Justify\n",
    "\n",
    "With your model trained, validated, and tested, you can now plot the predicted model output alongside the real data before the Mt. Mitchell station went offline. You can use this information to help you address your final model justification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6794c10-c2be-4aba-84c4-e98531ed8390",
   "metadata": {},
   "outputs": [],
   "source": [
    "### I want this plot to have this formatting\n",
    "### x5, vertically stacked subplots\n",
    "### Only showing obs @ MITC from 2024\n",
    "### Real data shown as #77aadd\n",
    "### Predictions shown as #ee8866\n",
    "\"\"\"\n",
    "xdates = pd.to_datetime(df['observation_datetime'])\n",
    "fig, ax = plt.subplots(1, 1, tight_layout=True)\n",
    "ax.plot(xdates[::100], df[selected_var][::100], label=var_dropdown.label, color='orange')\n",
    "ax.set_title(f\"Time Series of {var_dropdown.label} at {station_dropdown.value}\", fontsize=14)\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_ylabel(var_dropdown.label)\n",
    "ax.xaxis.set_major_locator(mdates.YearLocator())\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "plt.show()\n",
    "\"\"\"\n",
    "\n",
    "y_pred = trained_model().predict(X_true_test_filtered)\n",
    "\n",
    "fig, axs = plt.subplots(5, 1, figsize=(15, 10), sharex=True)\n",
    "labels = ['Air Temperature (Â°F)', 'Wind Speed (mph)', 'Wind Gust (mph)', 'RH (%)', 'Precipitation (in)']\n",
    "for i, (ax, label) in enumerate(zip(axs, labels)):\n",
    "    ax.plot(y_pred[:, i])\n",
    "    ax.set_ylabel(label)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "axs[-1].set_xlabel('Hours')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42551eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Create figure\n",
    "fig, axs = plt.subplots(5, 1, figsize=(15, 12), sharex=True)\n",
    "fig.subplots_adjust(hspace=0.1)\n",
    "\n",
    "labels = ['Air Temperature (Â°F)', 'Wind Speed (mph)', 'Wind Gust (mph)', 'RH (%)', 'Precipitation (in)']\n",
    "variables = ['MITC_airtemp_degF', 'MITC_windspeed_mph', 'MITC_windgust_mph', \n",
    "            'MITC_rh_percent', 'MITC_precip_in']\n",
    "\n",
    "for i, (ax, label, var) in enumerate(zip(axs, labels, variables)):\n",
    "    # Plot real data\n",
    "    mask = df[var].notna()\n",
    "    ax.plot(df.loc[mask, 'observation_datetime'], df.loc[mask, var], \n",
    "            color='#77aadd', alpha=1.0, label='Actual Data')\n",
    "    \n",
    "    # Add vertical line at September 28th without label\n",
    "    transition_date = pd.Timestamp('2024-09-28')\n",
    "    ax.axvline(x=transition_date, color='red', linestyle='-', alpha=0.5)\n",
    "    \n",
    "    ax.set_ylabel(label)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    if i == 0:  # Only add legend to the first subplot\n",
    "        ax.legend(loc='upper right')\n",
    "\n",
    "# Format x-axis to show only end of month ticks\n",
    "for ax in axs:\n",
    "    ax.xaxis.set_major_locator(mdates.MonthLocator(bymonthday=-1))\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%b'))\n",
    "\n",
    "plt.setp(axs[-1].xaxis.get_majorticklabels(), rotation=0)\n",
    "\n",
    "# Set x-axis limits to 2024\n",
    "plt.xlim(pd.Timestamp('2024-01-01'), pd.Timestamp('2024-12-31'))\n",
    "\n",
    "plt.suptitle('MITC Weather Variables 2024', y=0.95)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c598d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Create figure\n",
    "fig, axs = plt.subplots(5, 1, figsize=(15, 12), sharex=True)\n",
    "fig.subplots_adjust(hspace=0.1)\n",
    "\n",
    "labels = ['Air Temperature (Â°F)', 'Wind Speed (mph)', 'Wind Gust (mph)', 'RH (%)', 'Precipitation (in)']\n",
    "variables = ['MITC_airtemp_degF', 'MITC_windspeed_mph', 'MITC_windgust_mph', \n",
    "            'MITC_rh_percent', 'MITC_precip_in']\n",
    "\n",
    "# Get transition date (where NaNs start)\n",
    "transition_date = pd.Timestamp('2024-09-28')\n",
    "\n",
    "# Create date range for predictions starting from transition\n",
    "pred_dates = pd.date_range(start=transition_date, periods=len(y_pred), freq='H')\n",
    "\n",
    "for i, (ax, label, var) in enumerate(zip(axs, labels, variables)):\n",
    "    # Plot real data\n",
    "    mask = df[var].notna()\n",
    "    line1, = ax.plot(df.loc[mask, 'observation_datetime'], df.loc[mask, var], \n",
    "                     color='#77aadd', alpha=1.0, label='Actual')\n",
    "    \n",
    "    # Plot predictions (now with solid line)\n",
    "    line2, = ax.plot(pred_dates, y_pred[:, i], \n",
    "                     color='#ee8866', alpha=0.7, linestyle='-', label='Predicted')\n",
    "    \n",
    "    # Add vertical line at transition\n",
    "    ax.axvline(x=transition_date, color='red', linestyle='-', alpha=0.5)\n",
    "    \n",
    "    ax.set_ylabel(label)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    if i == 0:  # Only add legend to the first subplot\n",
    "        ax.legend(handles=[line1, line2], loc='upper right')\n",
    "\n",
    "# Format x-axis with ticks at end of month but labels in middle\n",
    "for ax in axs:\n",
    "    # Set major ticks at end of months\n",
    "    ax.xaxis.set_major_locator(mdates.MonthLocator(bymonthday=-1))\n",
    "    \n",
    "    # Set minor ticks (and labels) at middle of months\n",
    "    ax.xaxis.set_minor_locator(mdates.MonthLocator(bymonthday=15))\n",
    "    ax.xaxis.set_major_formatter(plt.NullFormatter())  # Hide major tick labels\n",
    "    ax.xaxis.set_minor_formatter(mdates.DateFormatter('%b'))  # Show month names on minor ticks\n",
    "\n",
    "plt.setp(axs[-1].xaxis.get_minorticklabels(), rotation=0)\n",
    "\n",
    "# Set x-axis limits to 2024\n",
    "plt.xlim(pd.Timestamp('2024-01-01'), pd.Timestamp('2024-12-31'))\n",
    "\n",
    "plt.suptitle('MITC Weather Variables 2024', y=0.95)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d4f576-7b33-4eb8-a958-0470baf0565b",
   "metadata": {},
   "source": [
    "#### Your final decision\n",
    "\n",
    "Given all your evaluation, it's time to make a final decision on whether you believe this model provides sufficient skill for the task at hand. Go back and review your problem statement. Does this model deliver the results needed?\n",
    "\n",
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "<p class=\"admonition-title\" style=\"font-weight:bold\">Exercise 3g</p>\n",
    "    <p>Open your <b>Machine Learning Model Handbook</b> to Exercise 3g. Then  make a final decision on whether this model delivers on the results needed with supporting justification. Include the following:\n",
    "    <ul>\n",
    "        <li>Which environmental variables had the best evaluation metrics? List some physical scientific reasons why this may be the case.</li>\n",
    "        <li>Is this model ready for use in the real world? Why or Why not?</li>\n",
    "        <li>What other possible changes could further improve this model?</li>\n",
    "    </ul>\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd61c48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
