{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from typing import Union, Dict, List\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin Data Prep (not for learners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module3_NC_dataEng.ipynb   hourly_data_MITC_2024.csv\n",
      "hourly_data_BEAR_2017.csv  hourly_data_MORG_2024.csv\n",
      "hourly_data_BEAR_2018.csv  hourly_data_NCAT_2017.csv\n",
      "hourly_data_BEAR_2019.csv  hourly_data_NCAT_2018.csv\n",
      "hourly_data_BEAR_2020.csv  hourly_data_NCAT_2019.csv\n",
      "hourly_data_BEAR_2021.csv  hourly_data_NCAT_2020.csv\n",
      "hourly_data_BEAR_2022.csv  hourly_data_NCAT_2021.csv\n",
      "hourly_data_BEAR_2023.csv  hourly_data_NCAT_2022.csv\n",
      "hourly_data_BEAR_2024.csv  hourly_data_NCAT_2023.csv\n",
      "hourly_data_BURN_2017.csv  hourly_data_NCAT_2024.csv\n",
      "hourly_data_BURN_2018.csv  hourly_data_SALI_2017.csv\n",
      "hourly_data_BURN_2019.csv  hourly_data_SALI_2018.csv\n",
      "hourly_data_BURN_2020.csv  hourly_data_SALI_2019.csv\n",
      "hourly_data_BURN_2021.csv  hourly_data_SALI_2020.csv\n",
      "hourly_data_BURN_2022.csv  hourly_data_SALI_2021.csv\n",
      "hourly_data_BURN_2023.csv  hourly_data_SALI_2022.csv\n",
      "hourly_data_BURN_2024.csv  hourly_data_SALI_2023.csv\n",
      "hourly_data_FRYI_2017.csv  hourly_data_SALI_2024.csv\n",
      "hourly_data_FRYI_2018.csv  hourly_data_SASS_2017.csv\n",
      "hourly_data_FRYI_2019.csv  hourly_data_SASS_2018.csv\n",
      "hourly_data_FRYI_2020.csv  hourly_data_SASS_2019.csv\n",
      "hourly_data_FRYI_2021.csv  hourly_data_SASS_2020.csv\n",
      "hourly_data_FRYI_2022.csv  hourly_data_SASS_2021.csv\n",
      "hourly_data_FRYI_2023.csv  hourly_data_SASS_2022.csv\n",
      "hourly_data_FRYI_2024.csv  hourly_data_SASS_2023.csv\n",
      "hourly_data_JEFF_2017.csv  hourly_data_SASS_2024.csv\n",
      "hourly_data_JEFF_2018.csv  hourly_data_UNCA_2019.csv\n",
      "hourly_data_JEFF_2019.csv  hourly_data_UNCA_2020.csv\n",
      "hourly_data_JEFF_2020.csv  hourly_data_UNCA_2021.csv\n",
      "hourly_data_JEFF_2021.csv  hourly_data_UNCA_2022.csv\n",
      "hourly_data_JEFF_2022.csv  hourly_data_UNCA_2023.csv\n",
      "hourly_data_JEFF_2023.csv  hourly_data_UNCA_2024.csv\n",
      "hourly_data_JEFF_2024.csv  hourly_data_WINE_2017.csv\n",
      "hourly_data_MITC_2017.csv  hourly_data_WINE_2018.csv\n",
      "hourly_data_MITC_2018.csv  hourly_data_WINE_2019.csv\n",
      "hourly_data_MITC_2019.csv  hourly_data_WINE_2020.csv\n",
      "hourly_data_MITC_2020.csv  hourly_data_WINE_2021.csv\n",
      "hourly_data_MITC_2021.csv  hourly_data_WINE_2022.csv\n",
      "hourly_data_MITC_2022.csv  hourly_data_WINE_2023.csv\n",
      "hourly_data_MITC_2023.csv  hourly_data_WINE_2024.csv\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_csvs(folder_path, concat_axis=0):\n",
    "    \"\"\"\n",
    "    Load and combine all CSV files from a folder into a single DataFrame.\n",
    "    Checks for column name consistency and strips headers from subsequent files.\n",
    "    \"\"\"\n",
    "    path = Path(folder_path)\n",
    "    dataframes = []\n",
    "    first_columns = None\n",
    "    file_sources = []  # Keep track of source files and their row counts\n",
    "    \n",
    "    for csv_file in path.glob('*.csv'):\n",
    "        try:\n",
    "            df = pd.read_csv(csv_file)\n",
    "            \n",
    "            # Clean column names (strip whitespace)\n",
    "            df.columns = df.columns.str.strip()\n",
    "            \n",
    "            # For the first file, store the column names\n",
    "            if first_columns is None:\n",
    "                first_columns = set(df.columns)\n",
    "                dataframes.append(df)\n",
    "            else:\n",
    "                # Check if current file has the same columns\n",
    "                current_columns = set(df.columns)\n",
    "                if current_columns != first_columns:\n",
    "                    print(f\"Warning: {csv_file.name} has different columns:\")\n",
    "                    print(f\"Missing columns: {first_columns - current_columns}\")\n",
    "                    print(f\"Extra columns: {current_columns - first_columns}\")\n",
    "                    print(\"Skipping this file...\")\n",
    "                    continue\n",
    "                \n",
    "                dataframes.append(df)\n",
    "            \n",
    "            # Store the source file information with correct row count\n",
    "            file_sources.extend([csv_file.name] * len(df))\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {csv_file.name}: {e}\")\n",
    "    \n",
    "    if not dataframes:\n",
    "        raise ValueError(\"No CSV files were successfully loaded\")\n",
    "    \n",
    "    # Combine all dataframes\n",
    "    combined_df = pd.concat(dataframes, axis=concat_axis, ignore_index=True)\n",
    "    \n",
    "    # Add source file information using our tracked sources\n",
    "    combined_df['source_file'] = file_sources\n",
    "    \n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully combined 670927 rows\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df = combine_csvs(\".\")\n",
    "    print(f\"Successfully combined {len(df)} rows\")\n",
    "except ValueError as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping MORG \n",
    "df = df[df['location_id']!='MORG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "location_id              object\n",
       "observation_datetime     object\n",
       "observation_timezone     object\n",
       "airtemp_degF            float64\n",
       "windspeed_avg_mph       float64\n",
       "winddgust_mph           float64\n",
       "rhavg_percent           float64\n",
       "precip_in               float64\n",
       "source_file              object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airtemp_degF</th>\n",
       "      <th>windspeed_avg_mph</th>\n",
       "      <th>winddgust_mph</th>\n",
       "      <th>rhavg_percent</th>\n",
       "      <th>precip_in</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>667398.000000</td>\n",
       "      <td>663464.000000</td>\n",
       "      <td>667605.000000</td>\n",
       "      <td>663960.000000</td>\n",
       "      <td>667403.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>52.726884</td>\n",
       "      <td>7.489819</td>\n",
       "      <td>10.011427</td>\n",
       "      <td>73.638571</td>\n",
       "      <td>0.007579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>15.699536</td>\n",
       "      <td>6.215288</td>\n",
       "      <td>8.048214</td>\n",
       "      <td>21.731251</td>\n",
       "      <td>0.047163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-136.840000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>41.900000</td>\n",
       "      <td>3.131800</td>\n",
       "      <td>4.297280</td>\n",
       "      <td>58.400000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>54.140000</td>\n",
       "      <td>6.039900</td>\n",
       "      <td>8.285850</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>64.040000</td>\n",
       "      <td>10.066500</td>\n",
       "      <td>13.636800</td>\n",
       "      <td>92.200000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>349.700000</td>\n",
       "      <td>57.490900</td>\n",
       "      <td>78.272600</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>4.140000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        airtemp_degF  windspeed_avg_mph  winddgust_mph  rhavg_percent  \\\n",
       "count  667398.000000      663464.000000  667605.000000  663960.000000   \n",
       "mean       52.726884           7.489819      10.011427      73.638571   \n",
       "std        15.699536           6.215288       8.048214      21.731251   \n",
       "min      -136.840000           0.000000       0.000000       0.000000   \n",
       "25%        41.900000           3.131800       4.297280      58.400000   \n",
       "50%        54.140000           6.039900       8.285850      79.000000   \n",
       "75%        64.040000          10.066500      13.636800      92.200000   \n",
       "max       349.700000          57.490900      78.272600     100.000000   \n",
       "\n",
       "           precip_in  \n",
       "count  667403.000000  \n",
       "mean        0.007579  \n",
       "std         0.047163  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         4.140000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "location_id                0\n",
      "observation_datetime       0\n",
      "observation_timezone       0\n",
      "airtemp_degF             207\n",
      "windspeed_avg_mph       4141\n",
      "winddgust_mph              0\n",
      "rhavg_percent           3645\n",
      "precip_in                202\n",
      "source_file                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the number of NaN values in each column\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Percentage of NaN values in each column (formatted):\n",
      "location_id             0.00\n",
      "observation_datetime    0.00\n",
      "observation_timezone    0.00\n",
      "airtemp_degF            0.03\n",
      "windspeed_avg_mph       0.62\n",
      "winddgust_mph           0.00\n",
      "rhavg_percent           0.55\n",
      "precip_in               0.03\n",
      "source_file             0.00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the percentage of NaN values in each column\n",
    "nan_percentage = (df.isna().sum() / len(df)) * 100\n",
    "\n",
    "# Optionally, format the output to 2 decimal places\n",
    "print(\"\\nPercentage of NaN values in each column (formatted):\")\n",
    "print(nan_percentage.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique stations: 10\n",
      "List of unique stations: ['BURN', 'NCAT', 'SALI', 'MITC', 'SASS', 'FRYI', 'JEFF', 'BEAR', 'WINE', 'UNCA']\n"
     ]
    }
   ],
   "source": [
    "num_unique_stations = df['location_id'].nunique()\n",
    "\n",
    "print(f\"Number of unique stations: {num_unique_stations}\")\n",
    "\n",
    "unique_stations_list = df['location_id'].unique().tolist()\n",
    "\n",
    "print(f\"List of unique stations: {unique_stations_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_id</th>\n",
       "      <th>observation_datetime</th>\n",
       "      <th>observation_timezone</th>\n",
       "      <th>airtemp_degF</th>\n",
       "      <th>windspeed_avg_mph</th>\n",
       "      <th>winddgust_mph</th>\n",
       "      <th>rhavg_percent</th>\n",
       "      <th>precip_in</th>\n",
       "      <th>source_file</th>\n",
       "      <th>date</th>\n",
       "      <th>day_index</th>\n",
       "      <th>hour_index</th>\n",
       "      <th>year_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BURN</td>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>EST</td>\n",
       "      <td>13.1000</td>\n",
       "      <td>5.8162</td>\n",
       "      <td>9.60120</td>\n",
       "      <td>69.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>hourly_data_BURN_2018.csv</td>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>365</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BURN</td>\n",
       "      <td>2018-01-01 01:00:00</td>\n",
       "      <td>EST</td>\n",
       "      <td>12.3800</td>\n",
       "      <td>4.9214</td>\n",
       "      <td>6.70876</td>\n",
       "      <td>69.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>hourly_data_BURN_2018.csv</td>\n",
       "      <td>2018-01-01 01:00:00</td>\n",
       "      <td>365</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BURN</td>\n",
       "      <td>2018-01-01 02:00:00</td>\n",
       "      <td>EST</td>\n",
       "      <td>10.9400</td>\n",
       "      <td>4.9214</td>\n",
       "      <td>5.69988</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>hourly_data_BURN_2018.csv</td>\n",
       "      <td>2018-01-01 02:00:00</td>\n",
       "      <td>365</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BURN</td>\n",
       "      <td>2018-01-01 03:00:00</td>\n",
       "      <td>EST</td>\n",
       "      <td>10.0400</td>\n",
       "      <td>3.3555</td>\n",
       "      <td>6.05108</td>\n",
       "      <td>72.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>hourly_data_BURN_2018.csv</td>\n",
       "      <td>2018-01-01 03:00:00</td>\n",
       "      <td>365</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BURN</td>\n",
       "      <td>2018-01-01 04:00:00</td>\n",
       "      <td>EST</td>\n",
       "      <td>9.3200</td>\n",
       "      <td>3.5792</td>\n",
       "      <td>5.21668</td>\n",
       "      <td>72.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>hourly_data_BURN_2018.csv</td>\n",
       "      <td>2018-01-01 04:00:00</td>\n",
       "      <td>365</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670922</th>\n",
       "      <td>UNCA</td>\n",
       "      <td>2019-12-31 19:00:00</td>\n",
       "      <td>EST</td>\n",
       "      <td>38.3684</td>\n",
       "      <td>0.4474</td>\n",
       "      <td>4.23911</td>\n",
       "      <td>53.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>hourly_data_UNCA_2019.csv</td>\n",
       "      <td>2019-12-31 19:00:00</td>\n",
       "      <td>1094</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670923</th>\n",
       "      <td>UNCA</td>\n",
       "      <td>2019-12-31 20:00:00</td>\n",
       "      <td>EST</td>\n",
       "      <td>37.1480</td>\n",
       "      <td>1.3422</td>\n",
       "      <td>4.67757</td>\n",
       "      <td>59.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>hourly_data_UNCA_2019.csv</td>\n",
       "      <td>2019-12-31 20:00:00</td>\n",
       "      <td>1094</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670924</th>\n",
       "      <td>UNCA</td>\n",
       "      <td>2019-12-31 21:00:00</td>\n",
       "      <td>EST</td>\n",
       "      <td>37.3298</td>\n",
       "      <td>2.2370</td>\n",
       "      <td>3.28839</td>\n",
       "      <td>61.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>hourly_data_UNCA_2019.csv</td>\n",
       "      <td>2019-12-31 21:00:00</td>\n",
       "      <td>1094</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670925</th>\n",
       "      <td>UNCA</td>\n",
       "      <td>2019-12-31 22:00:00</td>\n",
       "      <td>EST</td>\n",
       "      <td>36.4136</td>\n",
       "      <td>4.0266</td>\n",
       "      <td>6.50296</td>\n",
       "      <td>63.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>hourly_data_UNCA_2019.csv</td>\n",
       "      <td>2019-12-31 22:00:00</td>\n",
       "      <td>1094</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670926</th>\n",
       "      <td>UNCA</td>\n",
       "      <td>2019-12-31 23:00:00</td>\n",
       "      <td>EST</td>\n",
       "      <td>36.0464</td>\n",
       "      <td>3.8029</td>\n",
       "      <td>2.77612</td>\n",
       "      <td>64.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>hourly_data_UNCA_2019.csv</td>\n",
       "      <td>2019-12-31 23:00:00</td>\n",
       "      <td>1094</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>667605 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       location_id observation_datetime observation_timezone  airtemp_degF  \\\n",
       "0             BURN  2018-01-01 00:00:00                  EST       13.1000   \n",
       "1             BURN  2018-01-01 01:00:00                  EST       12.3800   \n",
       "2             BURN  2018-01-01 02:00:00                  EST       10.9400   \n",
       "3             BURN  2018-01-01 03:00:00                  EST       10.0400   \n",
       "4             BURN  2018-01-01 04:00:00                  EST        9.3200   \n",
       "...            ...                  ...                  ...           ...   \n",
       "670922        UNCA  2019-12-31 19:00:00                  EST       38.3684   \n",
       "670923        UNCA  2019-12-31 20:00:00                  EST       37.1480   \n",
       "670924        UNCA  2019-12-31 21:00:00                  EST       37.3298   \n",
       "670925        UNCA  2019-12-31 22:00:00                  EST       36.4136   \n",
       "670926        UNCA  2019-12-31 23:00:00                  EST       36.0464   \n",
       "\n",
       "        windspeed_avg_mph  winddgust_mph  rhavg_percent  precip_in  \\\n",
       "0                  5.8162        9.60120           69.1        0.0   \n",
       "1                  4.9214        6.70876           69.4        0.0   \n",
       "2                  4.9214        5.69988           71.3        0.0   \n",
       "3                  3.3555        6.05108           72.5        0.0   \n",
       "4                  3.5792        5.21668           72.7        0.0   \n",
       "...                   ...            ...            ...        ...   \n",
       "670922             0.4474        4.23911           53.6        0.0   \n",
       "670923             1.3422        4.67757           59.9        0.0   \n",
       "670924             2.2370        3.28839           61.1        0.0   \n",
       "670925             4.0266        6.50296           63.2        0.0   \n",
       "670926             3.8029        2.77612           64.3        0.0   \n",
       "\n",
       "                      source_file                date  day_index  hour_index  \\\n",
       "0       hourly_data_BURN_2018.csv 2018-01-01 00:00:00        365           0   \n",
       "1       hourly_data_BURN_2018.csv 2018-01-01 01:00:00        365           1   \n",
       "2       hourly_data_BURN_2018.csv 2018-01-01 02:00:00        365           2   \n",
       "3       hourly_data_BURN_2018.csv 2018-01-01 03:00:00        365           3   \n",
       "4       hourly_data_BURN_2018.csv 2018-01-01 04:00:00        365           4   \n",
       "...                           ...                 ...        ...         ...   \n",
       "670922  hourly_data_UNCA_2019.csv 2019-12-31 19:00:00       1094          19   \n",
       "670923  hourly_data_UNCA_2019.csv 2019-12-31 20:00:00       1094          20   \n",
       "670924  hourly_data_UNCA_2019.csv 2019-12-31 21:00:00       1094          21   \n",
       "670925  hourly_data_UNCA_2019.csv 2019-12-31 22:00:00       1094          22   \n",
       "670926  hourly_data_UNCA_2019.csv 2019-12-31 23:00:00       1094          23   \n",
       "\n",
       "        year_index  \n",
       "0                1  \n",
       "1                1  \n",
       "2                1  \n",
       "3                1  \n",
       "4                1  \n",
       "...            ...  \n",
       "670922           2  \n",
       "670923           2  \n",
       "670924           2  \n",
       "670925           2  \n",
       "670926           2  \n",
       "\n",
       "[667605 rows x 13 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert 'date' column to datetime\n",
    "df['date'] = pd.to_datetime(df['observation_datetime'])\n",
    "\n",
    "# Find the lowest date\n",
    "lowest_date = df['date'].min()\n",
    "\n",
    "# Create a new column 'day_index' starting from 0\n",
    "df['day_index'] = (df['date'] - lowest_date).dt.days\n",
    "\n",
    "# Create a new column 'hour_index' going from 0 to 23\n",
    "df['hour_index'] = df['date'].dt.hour\n",
    "\n",
    "# Create a new column 'year_index' starting from 0\n",
    "df['year_index'] = df['date'].dt.year - df['date'].dt.year.min()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['location_id', 'observation_datetime', 'observation_timezone',\n",
       "       'airtemp_degF', 'windspeed_avg_mph', 'winddgust_mph', 'rhavg_percent',\n",
       "       'precip_in', 'source_file', 'date', 'day_index', 'hour_index',\n",
       "       'year_index'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_station_data(df, station):\n",
    "    print(f\"Processing station: {station}\")\n",
    "    print(f\"Shape of df before filtering: {df.shape}\")\n",
    "    \n",
    "    # Filter the DataFrame for the specific station\n",
    "    df_station = df[df['location_id'] == station].copy()\n",
    "    \n",
    "    print(f\"Shape of df_station after filtering: {df_station.shape}\")\n",
    "    \n",
    "    if df_station.empty:\n",
    "        print(f\"No data found for station {station}\")\n",
    "        return None\n",
    "    \n",
    "    # Drop columns we don't need\n",
    "    columns_to_drop = ['location_id', 'source_file', 'observation_timezone']\n",
    "    df_station = df_station.drop(columns=[col for col in columns_to_drop if col in df_station.columns])\n",
    "    \n",
    "    # Define columns we want to keep unchanged (no station suffix)\n",
    "    unchanged_cols = [\n",
    "        'date', \n",
    "        'day_index', \n",
    "        'hour_index', \n",
    "        'year_index',\n",
    "        'observation_datetime'\n",
    "    ]\n",
    "    \n",
    "    # Create mapping for measurement columns to their new names\n",
    "    measurement_renames = {\n",
    "        'airtemp_degF': f'{station}_airtemp_degF',\n",
    "        'windspeed_avg_mph': f'{station}_windspeed_mph',\n",
    "        'winddgust_mph': f'{station}_windgust_mph',\n",
    "        'rhavg_percent': f'{station}_rh_percent',\n",
    "        'precip_in': f'{station}_precip_in'\n",
    "    }\n",
    "    \n",
    "    # Apply the measurement-specific renames\n",
    "    df_station = df_station.rename(columns=measurement_renames)\n",
    "    \n",
    "    return df_station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of df: (667605, 13)\n",
      "Columns in df: Index(['location_id', 'observation_datetime', 'observation_timezone',\n",
      "       'airtemp_degF', 'windspeed_avg_mph', 'winddgust_mph', 'rhavg_percent',\n",
      "       'precip_in', 'source_file', 'date', 'day_index', 'hour_index',\n",
      "       'year_index'],\n",
      "      dtype='object')\n",
      "Unique values in 'Station' column: ['BURN' 'NCAT' 'SALI' 'MITC' 'SASS' 'FRYI' 'JEFF' 'BEAR' 'WINE' 'UNCA']\n",
      "unique_stations_list: ['BURN', 'NCAT', 'SALI', 'MITC', 'SASS', 'FRYI', 'JEFF', 'BEAR', 'WINE', 'UNCA']\n"
     ]
    }
   ],
   "source": [
    "# Debugging: Print information about df and unique_stations_list\n",
    "print(f\"Shape of df: {df.shape}\")\n",
    "print(f\"Columns in df: {df.columns}\")\n",
    "print(f\"Unique values in 'Station' column: {df['location_id'].unique()}\")\n",
    "print(f\"unique_stations_list: {unique_stations_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing station: BURN\n",
      "Shape of df before filtering: (667605, 13)\n",
      "Shape of df_station after filtering: (68596, 13)\n",
      "Station BURN processed successfully!\n",
      "Processing station: NCAT\n",
      "Shape of df before filtering: (667605, 13)\n",
      "Shape of df_station after filtering: (69623, 13)\n",
      "Station NCAT processed successfully!\n",
      "Processing station: SALI\n",
      "Shape of df before filtering: (667605, 13)\n",
      "Shape of df_station after filtering: (69496, 13)\n",
      "Station SALI processed successfully!\n",
      "Processing station: MITC\n",
      "Shape of df before filtering: (667605, 13)\n",
      "Shape of df_station after filtering: (67979, 13)\n",
      "Station MITC processed successfully!\n",
      "Processing station: SASS\n",
      "Shape of df before filtering: (667605, 13)\n",
      "Shape of df_station after filtering: (69066, 13)\n",
      "Station SASS processed successfully!\n",
      "Processing station: FRYI\n",
      "Shape of df before filtering: (667605, 13)\n",
      "Shape of df_station after filtering: (69282, 13)\n",
      "Station FRYI processed successfully!\n",
      "Processing station: JEFF\n",
      "Shape of df before filtering: (667605, 13)\n",
      "Shape of df_station after filtering: (69110, 13)\n",
      "Station JEFF processed successfully!\n",
      "Processing station: BEAR\n",
      "Shape of df before filtering: (667605, 13)\n",
      "Shape of df_station after filtering: (69660, 13)\n",
      "Station BEAR processed successfully!\n",
      "Processing station: WINE\n",
      "Shape of df before filtering: (667605, 13)\n",
      "Shape of df_station after filtering: (68510, 13)\n",
      "Station WINE processed successfully!\n",
      "Processing station: UNCA\n",
      "Shape of df before filtering: (667605, 13)\n",
      "Shape of df_station after filtering: (46283, 13)\n",
      "Station UNCA processed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty DataFrame to store the merged results\n",
    "merged_df = pd.DataFrame()\n",
    "\n",
    "# Define columns that should not be renamed (merge keys)\n",
    "unchanged_cols = ['date', 'day_index', 'hour_index', 'year_index', 'observation_datetime']\n",
    "\n",
    "# Iterate through each station in the list of unique stations\n",
    "for station in unique_stations_list:\n",
    "    # Process the data for the current station\n",
    "    processed_df = process_station_data(df, station)\n",
    "    \n",
    "    if processed_df is not None and not processed_df.empty:\n",
    "        # Note: Removed the rename step since it's handled in process_station_data\n",
    "        \n",
    "        if merged_df.empty:\n",
    "            merged_df = processed_df\n",
    "        else:\n",
    "            merged_df = pd.merge(merged_df, processed_df, \n",
    "                               on=unchanged_cols, \n",
    "                               how='outer')\n",
    "        \n",
    "        print(f\"Station {station} processed successfully!\")\n",
    "    else:\n",
    "        print(f\"Skipping empty or None result for station {station}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['observation_datetime', 'BURN_airtemp_degF', 'BURN_windspeed_mph',\n",
       "       'BURN_windgust_mph', 'BURN_rh_percent', 'BURN_precip_in', 'date',\n",
       "       'day_index', 'hour_index', 'year_index', 'NCAT_airtemp_degF',\n",
       "       'NCAT_windspeed_mph', 'NCAT_windgust_mph', 'NCAT_rh_percent',\n",
       "       'NCAT_precip_in', 'SALI_airtemp_degF', 'SALI_windspeed_mph',\n",
       "       'SALI_windgust_mph', 'SALI_rh_percent', 'SALI_precip_in',\n",
       "       'MITC_airtemp_degF', 'MITC_windspeed_mph', 'MITC_windgust_mph',\n",
       "       'MITC_rh_percent', 'MITC_precip_in', 'SASS_airtemp_degF',\n",
       "       'SASS_windspeed_mph', 'SASS_windgust_mph', 'SASS_rh_percent',\n",
       "       'SASS_precip_in', 'FRYI_airtemp_degF', 'FRYI_windspeed_mph',\n",
       "       'FRYI_windgust_mph', 'FRYI_rh_percent', 'FRYI_precip_in',\n",
       "       'JEFF_airtemp_degF', 'JEFF_windspeed_mph', 'JEFF_windgust_mph',\n",
       "       'JEFF_rh_percent', 'JEFF_precip_in', 'BEAR_airtemp_degF',\n",
       "       'BEAR_windspeed_mph', 'BEAR_windgust_mph', 'BEAR_rh_percent',\n",
       "       'BEAR_precip_in', 'WINE_airtemp_degF', 'WINE_windspeed_mph',\n",
       "       'WINE_windgust_mph', 'WINE_rh_percent', 'WINE_precip_in',\n",
       "       'UNCA_airtemp_degF', 'UNCA_windspeed_mph', 'UNCA_windgust_mph',\n",
       "       'UNCA_rh_percent', 'UNCA_precip_in'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BURN_airtemp_degF</th>\n",
       "      <th>BURN_windspeed_mph</th>\n",
       "      <th>BURN_windgust_mph</th>\n",
       "      <th>BURN_rh_percent</th>\n",
       "      <th>BURN_precip_in</th>\n",
       "      <th>date</th>\n",
       "      <th>day_index</th>\n",
       "      <th>hour_index</th>\n",
       "      <th>year_index</th>\n",
       "      <th>NCAT_airtemp_degF</th>\n",
       "      <th>...</th>\n",
       "      <th>WINE_airtemp_degF</th>\n",
       "      <th>WINE_windspeed_mph</th>\n",
       "      <th>WINE_windgust_mph</th>\n",
       "      <th>WINE_rh_percent</th>\n",
       "      <th>WINE_precip_in</th>\n",
       "      <th>UNCA_airtemp_degF</th>\n",
       "      <th>UNCA_windspeed_mph</th>\n",
       "      <th>UNCA_windgust_mph</th>\n",
       "      <th>UNCA_rh_percent</th>\n",
       "      <th>UNCA_precip_in</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>68596.000000</td>\n",
       "      <td>68363.000000</td>\n",
       "      <td>68596.000000</td>\n",
       "      <td>68336.000000</td>\n",
       "      <td>68596.000000</td>\n",
       "      <td>69760</td>\n",
       "      <td>69760.00000</td>\n",
       "      <td>69760.000000</td>\n",
       "      <td>69760.000000</td>\n",
       "      <td>69623.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>68501.000000</td>\n",
       "      <td>68440.000000</td>\n",
       "      <td>68510.000000</td>\n",
       "      <td>68413.000000</td>\n",
       "      <td>68510.000000</td>\n",
       "      <td>46283.000000</td>\n",
       "      <td>46230.000000</td>\n",
       "      <td>46283.000000</td>\n",
       "      <td>46266.000000</td>\n",
       "      <td>46283.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.372067</td>\n",
       "      <td>4.308732</td>\n",
       "      <td>5.981867</td>\n",
       "      <td>71.871230</td>\n",
       "      <td>0.006658</td>\n",
       "      <td>2020-12-24 13:38:27.591743232</td>\n",
       "      <td>1453.08922</td>\n",
       "      <td>11.499713</td>\n",
       "      <td>3.483214</td>\n",
       "      <td>60.237652</td>\n",
       "      <td>...</td>\n",
       "      <td>48.570732</td>\n",
       "      <td>6.108281</td>\n",
       "      <td>9.460373</td>\n",
       "      <td>76.972752</td>\n",
       "      <td>0.007932</td>\n",
       "      <td>56.637852</td>\n",
       "      <td>3.391849</td>\n",
       "      <td>5.165646</td>\n",
       "      <td>72.357061</td>\n",
       "      <td>0.004006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-4.180000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.460000</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.980000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.740000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>42.620000</td>\n",
       "      <td>1.118500</td>\n",
       "      <td>1.709070</td>\n",
       "      <td>57.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2018-12-28 21:45:00</td>\n",
       "      <td>726.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>48.020000</td>\n",
       "      <td>...</td>\n",
       "      <td>39.380000</td>\n",
       "      <td>3.355500</td>\n",
       "      <td>5.393410</td>\n",
       "      <td>62.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.603500</td>\n",
       "      <td>1.342200</td>\n",
       "      <td>1.899210</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>56.480000</td>\n",
       "      <td>4.026600</td>\n",
       "      <td>5.306160</td>\n",
       "      <td>75.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-12-24 15:30:00</td>\n",
       "      <td>1453.00000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>62.060000</td>\n",
       "      <td>...</td>\n",
       "      <td>50.360000</td>\n",
       "      <td>5.592500</td>\n",
       "      <td>8.637060</td>\n",
       "      <td>86.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>58.496000</td>\n",
       "      <td>2.684400</td>\n",
       "      <td>4.019890</td>\n",
       "      <td>76.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>66.200000</td>\n",
       "      <td>6.487300</td>\n",
       "      <td>9.120250</td>\n",
       "      <td>89.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2022-12-21 07:15:00</td>\n",
       "      <td>2180.00000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>59.360000</td>\n",
       "      <td>8.276900</td>\n",
       "      <td>12.715100</td>\n",
       "      <td>94.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>67.820000</td>\n",
       "      <td>4.697700</td>\n",
       "      <td>7.379860</td>\n",
       "      <td>91.700000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.140000</td>\n",
       "      <td>23.488500</td>\n",
       "      <td>41.049000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>2.160000</td>\n",
       "      <td>2024-12-16 23:00:00</td>\n",
       "      <td>2906.00000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>95.540000</td>\n",
       "      <td>...</td>\n",
       "      <td>129.920000</td>\n",
       "      <td>23.712200</td>\n",
       "      <td>41.787200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.880000</td>\n",
       "      <td>349.700000</td>\n",
       "      <td>17.448600</td>\n",
       "      <td>44.650500</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>2.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>15.607199</td>\n",
       "      <td>3.348480</td>\n",
       "      <td>5.098407</td>\n",
       "      <td>20.420981</td>\n",
       "      <td>0.043201</td>\n",
       "      <td>NaN</td>\n",
       "      <td>839.18155</td>\n",
       "      <td>6.922258</td>\n",
       "      <td>2.283490</td>\n",
       "      <td>16.047654</td>\n",
       "      <td>...</td>\n",
       "      <td>13.799802</td>\n",
       "      <td>3.517905</td>\n",
       "      <td>5.475936</td>\n",
       "      <td>23.558845</td>\n",
       "      <td>0.043443</td>\n",
       "      <td>15.353779</td>\n",
       "      <td>2.647189</td>\n",
       "      <td>4.485656</td>\n",
       "      <td>21.132323</td>\n",
       "      <td>0.032385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       BURN_airtemp_degF  BURN_windspeed_mph  BURN_windgust_mph  \\\n",
       "count       68596.000000        68363.000000       68596.000000   \n",
       "mean           54.372067            4.308732           5.981867   \n",
       "min            -4.180000            0.000000           0.000000   \n",
       "25%            42.620000            1.118500           1.709070   \n",
       "50%            56.480000            4.026600           5.306160   \n",
       "75%            66.200000            6.487300           9.120250   \n",
       "max            90.140000           23.488500          41.049000   \n",
       "std            15.607199            3.348480           5.098407   \n",
       "\n",
       "       BURN_rh_percent  BURN_precip_in                           date  \\\n",
       "count     68336.000000    68596.000000                          69760   \n",
       "mean         71.871230        0.006658  2020-12-24 13:38:27.591743232   \n",
       "min           3.100000        0.000000            2017-01-01 00:00:00   \n",
       "25%          57.200000        0.000000            2018-12-28 21:45:00   \n",
       "50%          75.300000        0.000000            2020-12-24 15:30:00   \n",
       "75%          89.400000        0.000000            2022-12-21 07:15:00   \n",
       "max         100.000000        2.160000            2024-12-16 23:00:00   \n",
       "std          20.420981        0.043201                            NaN   \n",
       "\n",
       "         day_index    hour_index    year_index  NCAT_airtemp_degF  ...  \\\n",
       "count  69760.00000  69760.000000  69760.000000       69623.000000  ...   \n",
       "mean    1453.08922     11.499713      3.483214          60.237652  ...   \n",
       "min        0.00000      0.000000      0.000000           4.460000  ...   \n",
       "25%      726.00000      5.000000      1.000000          48.020000  ...   \n",
       "50%     1453.00000     11.000000      3.000000          62.060000  ...   \n",
       "75%     2180.00000     17.000000      5.000000          72.500000  ...   \n",
       "max     2906.00000     23.000000      7.000000          95.540000  ...   \n",
       "std      839.18155      6.922258      2.283490          16.047654  ...   \n",
       "\n",
       "       WINE_airtemp_degF  WINE_windspeed_mph  WINE_windgust_mph  \\\n",
       "count       68501.000000        68440.000000       68510.000000   \n",
       "mean           48.570732            6.108281           9.460373   \n",
       "min           -14.980000            0.000000           0.000000   \n",
       "25%            39.380000            3.355500           5.393410   \n",
       "50%            50.360000            5.592500           8.637060   \n",
       "75%            59.360000            8.276900          12.715100   \n",
       "max           129.920000           23.712200          41.787200   \n",
       "std            13.799802            3.517905           5.475936   \n",
       "\n",
       "       WINE_rh_percent  WINE_precip_in  UNCA_airtemp_degF  UNCA_windspeed_mph  \\\n",
       "count     68413.000000    68510.000000       46283.000000        46230.000000   \n",
       "mean         76.972752        0.007932          56.637852            3.391849   \n",
       "min           0.000000        0.000000          -2.740000            0.000000   \n",
       "25%          62.900000        0.000000          45.603500            1.342200   \n",
       "50%          86.700000        0.000000          58.496000            2.684400   \n",
       "75%          94.300000        0.000000          67.820000            4.697700   \n",
       "max         100.000000        1.880000         349.700000           17.448600   \n",
       "std          23.558845        0.043443          15.353779            2.647189   \n",
       "\n",
       "       UNCA_windgust_mph  UNCA_rh_percent  UNCA_precip_in  \n",
       "count       46283.000000     46266.000000    46283.000000  \n",
       "mean            5.165646        72.357061        0.004006  \n",
       "min             0.000000         1.100000        0.000000  \n",
       "25%             1.899210        57.000000        0.000000  \n",
       "50%             4.019890        76.500000        0.000000  \n",
       "75%             7.379860        91.700000        0.000000  \n",
       "max            44.650500       100.000000        2.020000  \n",
       "std             4.485656        21.132323        0.032385  \n",
       "\n",
       "[8 rows x 54 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting data for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_with_rolling_average_and_median(df, window_size=5):\n",
    "    df_imputed = df.copy()\n",
    "    \n",
    "    for column in df_imputed.columns:\n",
    "        if df_imputed[column].dtype.kind in 'biufc':  # Check if column is numeric\n",
    "            # Create a Series with the rolling mean\n",
    "            rolling_mean = df_imputed[column].rolling(window=window_size, center=True, min_periods=1).mean()\n",
    "            \n",
    "            # Use the rolling mean to fill NaN values\n",
    "            df_imputed[column] = df_imputed[column].fillna(rolling_mean)\n",
    "            \n",
    "            # If any NaNs remain, fill with the median of the column\n",
    "            if df_imputed[column].isna().any():\n",
    "                column_median = df_imputed[column].median()\n",
    "                df_imputed[column] = df_imputed[column].fillna(column_median)\n",
    "                print(f\"Column '{column}': Filled remaining NaNs with median ({column_median})\")\n",
    "        else:\n",
    "            print(f\"Column '{column}' is non-numeric. Skipping imputation.\")\n",
    "    \n",
    "    return df_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'observation_datetime' is non-numeric. Skipping imputation.\n",
      "Column 'BURN_airtemp_degF': Filled remaining NaNs with median (56.48)\n",
      "Column 'BURN_windspeed_mph': Filled remaining NaNs with median (4.0266)\n",
      "Column 'BURN_windgust_mph': Filled remaining NaNs with median (5.30616)\n",
      "Column 'BURN_rh_percent': Filled remaining NaNs with median (75.3)\n",
      "Column 'BURN_precip_in': Filled remaining NaNs with median (0.0)\n",
      "Column 'date' is non-numeric. Skipping imputation.\n",
      "Column 'NCAT_airtemp_degF': Filled remaining NaNs with median (62.06)\n",
      "Column 'NCAT_windspeed_mph': Filled remaining NaNs with median (4.0266)\n",
      "Column 'NCAT_windgust_mph': Filled remaining NaNs with median (5.17418)\n",
      "Column 'NCAT_rh_percent': Filled remaining NaNs with median (70.8)\n",
      "Column 'NCAT_precip_in': Filled remaining NaNs with median (0.0)\n",
      "Column 'SALI_airtemp_degF': Filled remaining NaNs with median (62.06)\n",
      "Column 'SALI_windspeed_mph': Filled remaining NaNs with median (2.6844)\n",
      "Column 'SALI_windgust_mph': Filled remaining NaNs with median (3.33313)\n",
      "Column 'SALI_rh_percent': Filled remaining NaNs with median (77.5)\n",
      "Column 'SALI_precip_in': Filled remaining NaNs with median (0.0)\n",
      "Column 'MITC_airtemp_degF': Filled remaining NaNs with median (47.48)\n",
      "Column 'MITC_windspeed_mph': Filled remaining NaNs with median (11.6324)\n",
      "Column 'MITC_windgust_mph': Filled remaining NaNs with median (14.7329)\n",
      "Column 'MITC_rh_percent': Filled remaining NaNs with median (87.1)\n",
      "Column 'MITC_precip_in': Filled remaining NaNs with median (0.0)\n",
      "Column 'SASS_airtemp_degF': Filled remaining NaNs with median (56.3)\n",
      "Column 'SASS_windspeed_mph': Filled remaining NaNs with median (6.4873)\n",
      "Column 'SASS_windgust_mph': Filled remaining NaNs with median (8.63706)\n",
      "Column 'SASS_rh_percent': Filled remaining NaNs with median (75.3)\n",
      "Column 'SASS_precip_in': Filled remaining NaNs with median (0.0)\n",
      "Column 'FRYI_airtemp_degF': Filled remaining NaNs with median (51.26)\n",
      "Column 'FRYI_windspeed_mph': Filled remaining NaNs with median (8.5006)\n",
      "Column 'FRYI_windgust_mph': Filled remaining NaNs with median (11.4445)\n",
      "Column 'FRYI_rh_percent': Filled remaining NaNs with median (82.5)\n",
      "Column 'FRYI_precip_in': Filled remaining NaNs with median (0.0)\n",
      "Column 'JEFF_airtemp_degF': Filled remaining NaNs with median (51.26)\n",
      "Column 'JEFF_windspeed_mph': Filled remaining NaNs with median (8.948)\n",
      "Column 'JEFF_windgust_mph': Filled remaining NaNs with median (12.4959)\n",
      "Column 'JEFF_rh_percent': Filled remaining NaNs with median (79.0)\n",
      "Column 'JEFF_precip_in': Filled remaining NaNs with median (0.0)\n",
      "Column 'BEAR_airtemp_degF': Filled remaining NaNs with median (53.42)\n",
      "Column 'BEAR_windspeed_mph': Filled remaining NaNs with median (10.2902)\n",
      "Column 'BEAR_windgust_mph': Filled remaining NaNs with median (12.6279)\n",
      "Column 'BEAR_rh_percent': Filled remaining NaNs with median (79.1)\n",
      "Column 'BEAR_precip_in': Filled remaining NaNs with median (0.0)\n",
      "Column 'WINE_airtemp_degF': Filled remaining NaNs with median (50.36)\n",
      "Column 'WINE_windspeed_mph': Filled remaining NaNs with median (5.5925)\n",
      "Column 'WINE_windgust_mph': Filled remaining NaNs with median (8.63706)\n",
      "Column 'WINE_rh_percent': Filled remaining NaNs with median (86.7)\n",
      "Column 'WINE_precip_in': Filled remaining NaNs with median (0.0)\n",
      "Column 'UNCA_airtemp_degF': Filled remaining NaNs with median (58.514)\n",
      "Column 'UNCA_windspeed_mph': Filled remaining NaNs with median (2.6844)\n",
      "Column 'UNCA_windgust_mph': Filled remaining NaNs with median (4.01989)\n",
      "Column 'UNCA_rh_percent': Filled remaining NaNs with median (76.5)\n",
      "Column 'UNCA_precip_in': Filled remaining NaNs with median (0.0)\n"
     ]
    }
   ],
   "source": [
    "df_imputed = impute_with_rolling_average_and_median(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['observation_datetime', 'BURN_airtemp_degF', 'BURN_windspeed_mph',\n",
       "       'BURN_windgust_mph', 'BURN_rh_percent', 'BURN_precip_in', 'date',\n",
       "       'day_index', 'hour_index', 'year_index', 'NCAT_airtemp_degF',\n",
       "       'NCAT_windspeed_mph', 'NCAT_windgust_mph', 'NCAT_rh_percent',\n",
       "       'NCAT_precip_in', 'SALI_airtemp_degF', 'SALI_windspeed_mph',\n",
       "       'SALI_windgust_mph', 'SALI_rh_percent', 'SALI_precip_in',\n",
       "       'MITC_airtemp_degF', 'MITC_windspeed_mph', 'MITC_windgust_mph',\n",
       "       'MITC_rh_percent', 'MITC_precip_in', 'SASS_airtemp_degF',\n",
       "       'SASS_windspeed_mph', 'SASS_windgust_mph', 'SASS_rh_percent',\n",
       "       'SASS_precip_in', 'FRYI_airtemp_degF', 'FRYI_windspeed_mph',\n",
       "       'FRYI_windgust_mph', 'FRYI_rh_percent', 'FRYI_precip_in',\n",
       "       'JEFF_airtemp_degF', 'JEFF_windspeed_mph', 'JEFF_windgust_mph',\n",
       "       'JEFF_rh_percent', 'JEFF_precip_in', 'BEAR_airtemp_degF',\n",
       "       'BEAR_windspeed_mph', 'BEAR_windgust_mph', 'BEAR_rh_percent',\n",
       "       'BEAR_precip_in', 'WINE_airtemp_degF', 'WINE_windspeed_mph',\n",
       "       'WINE_windgust_mph', 'WINE_rh_percent', 'WINE_precip_in',\n",
       "       'UNCA_airtemp_degF', 'UNCA_windspeed_mph', 'UNCA_windgust_mph',\n",
       "       'UNCA_rh_percent', 'UNCA_precip_in'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imputed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_mitc_columns(df, cutoff_date='2024-09-28'):\n",
    "    # Make a copy to avoid modifying the original DataFrame\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    # Get list of columns containing 'MITC'\n",
    "    mitc_columns = [col for col in df.columns if 'MITC' in col]\n",
    "    print(f\"Found MITC columns: {mitc_columns}\")\n",
    "    \n",
    "    # Create mask for dates after cutoff\n",
    "    cutoff_dt = pd.to_datetime(cutoff_date)\n",
    "    after_cutoff_mask = df_processed['date'] > cutoff_dt\n",
    "    \n",
    "    # Calculate number of days\n",
    "    dates_after_cutoff = df_processed.loc[after_cutoff_mask, 'date']\n",
    "    num_days = len(pd.date_range(dates_after_cutoff.min(), dates_after_cutoff.max()).date)\n",
    "    \n",
    "    print(f\"Date range in data: {df_processed['date'].min()} to {df_processed['date'].max()}\")\n",
    "    print(f\"Cutoff date: {cutoff_dt}\")\n",
    "    print(f\"Number of rows after cutoff: {after_cutoff_mask.sum()}\")\n",
    "    print(f\"Number of days being NaN'd: {num_days}\")\n",
    "    print(f\"Hours being NaN'd: {after_cutoff_mask.sum()}\")\n",
    "    print(f\"Average hours per day being NaN'd: {after_cutoff_mask.sum() / num_days:.2f}\")\n",
    "    \n",
    "    # Set values to NaN for all MITC columns after cutoff date\n",
    "    for col in mitc_columns:\n",
    "        df_processed.loc[after_cutoff_mask, col] = np.nan\n",
    "        \n",
    "    return df_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found MITC columns: ['MITC_airtemp_degF', 'MITC_windspeed_mph', 'MITC_windgust_mph', 'MITC_rh_percent', 'MITC_precip_in']\n",
      "Date range in data: 2017-01-01 00:00:00 to 2024-12-16 23:00:00\n",
      "Cutoff date: 2024-09-28 00:00:00\n",
      "Number of rows after cutoff: 1919\n",
      "Number of days being NaN'd: 80\n",
      "Hours being NaN'd: 1919\n",
      "Average hours per day being NaN'd: 23.99\n"
     ]
    }
   ],
   "source": [
    "df_imputed = process_mitc_columns(df_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed.to_parquet('../processed_data/NC_processed_data_1_6.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
