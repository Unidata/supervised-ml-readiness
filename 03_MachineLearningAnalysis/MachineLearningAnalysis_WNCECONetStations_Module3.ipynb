{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9805bfd2-b31d-4b2f-b325-a409c27f96c7",
   "metadata": {},
   "source": [
    "<img src=\"https://elearning.unidata.ucar.edu/dataeLearning/Cybertraining/analysis/media/NSF-Unidata_lockup_vertical_2023.png\" width=\"150px\" align=\"right\">\n",
    "\n",
    "# Machine Learning Analysis in the Earth Systems Sciences\n",
    "\n",
    "In this module, you are tasked with planning, implementing, and evaluating a machine learning solution for a real-world scenario. Given pre-configured code blocks and prepared data, you will create a problem statement, explore the data, experiment with model development, and ultimately make a recommendation on the utility of machine learning for your scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e3747f-a6cf-4326-9e5c-67117de117b9",
   "metadata": {},
   "source": [
    "# Damaged weather station in western North Carolina\n",
    "\n",
    "In the fall of 2024, a major hurricane devastated western North Carolina and Appalachia. This caused widespread damage, including damage to important weather observing instruments. Play the video below to learn more about the situation, and how machine learning might be a helpful tool.<br><i>Video opens in a new tab.</i>\n",
    "\n",
    "<a href=\"https://elearning.unidata.ucar.edu/dataeLearning/Cybertraining/analysis/media/wncvideo\" target=\"blank\"><img src=\"https://elearning.unidata.ucar.edu/dataeLearning/Cybertraining/analysis/media/stationsslides_thumb.png\" width=\"600 px\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://www.google.com/url?q=https://docs.google.com/document/d/e/2PACX-1vRfYtUFjLVfNadQ0nvUv4E8MzfaXmQwt_WcP0haCo5bH1J0zGZiupiJz7XuLsun2BqN-g_ubbACpx6p/pub&sa=D&source=docs&ust=1738596555923034&usg=AOvVaw2xJ1FEg1SflwC6i3P5uQqD\" target=\"blank\">Transcript</a>\n",
    "\n",
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "<p class=\"admonition-title\" style=\"font-weight:bold\">What is a data engineer?</p>\n",
    "    <p>Your team includes yourself, your team lead, and a data engineer. Data engineering is an emerging career that encompasses the collection, storage, and pre-processing of data in data science disciplines. You will see the type of work that the data engineer on your team does in <i>Part 2: Data Handling.</i></p>\n",
    "    <p><a href=\"https://www.mongodb.com/resources/basics/data-engineering#what-is-data-engineering\" target=\"blank\">Learn more</a></p>\n",
    "</div>\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5cad94-efb5-4291-830e-64a8ad7ea483",
   "metadata": {},
   "source": [
    "Now you will begin the process of following the supervised machine learning model framework to address this task, starting with <b>problem framing</b>.\n",
    "<center><a href=\"https://elearning.unidata.ucar.edu/dataeLearning/Cybertraining/analysis/media/RevisedFull_NOPROCESS_.png\" target=\"blank\"><img src=\"https://elearning.unidata.ucar.edu/dataeLearning/Cybertraining/analysis/media/RevisedFull_NOPROCESS_.png\"></a><br><i>Click to enlarge</i></center>\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8ffff5-7731-4142-bd98-d9f5db95dd13",
   "metadata": {},
   "source": [
    "## Part 1: Problem Framing\n",
    "\n",
    "Based on the information provided in the video, which type of machine learning analysis is most appropriate for this scenario? \n",
    "\n",
    "> **Instructions**\n",
    "> \n",
    "> Execute the two cells below. After executing `display_knowledgecheck()`, select the corresponding button to check your understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bee4cd7-65d4-47b5-b461-48d17890a0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First import the Python tools needed to display the buttons\n",
    "# This cell may take a moment to complete\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output, HTML, IFrame\n",
    "\n",
    "from analysis_tech import display_knowledgecheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8d6ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_knowledgecheck()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df781998-2df2-46ab-9cac-68a65930dd9c",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c41fcf-e3c0-488e-9c71-de6c5d088b12",
   "metadata": {},
   "source": [
    "#### Problem framing questions\n",
    "As a part of the problem framing step, we must answer a series of questions to ensure we're creating the best solution for this scenario. \n",
    "\n",
    "***Does a simpler solution exist?***\n",
    "\n",
    "&emsp;From the video, we know that your team has already completed a preliminary analysis that averaged values from nearby stations to Mt Mitchell. While these results showed some skill, there is room for improvement. \n",
    "\n",
    "***Can machine learning requirements be met?***\n",
    "\n",
    "&emsp;The NC ECONet data provider has decades of hourly data available from several weather stations. This is sufficient for your model. \n",
    "\n",
    "***Which scientific question should be answered?***\n",
    "\n",
    "&emsp;You will answer this question in **Exercise 1** below. \n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd95337-12f5-4e9b-a786-979ebad08b20",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "<p class=\"admonition-title\" style=\"font-weight:bold\">Exercise 1</p>\n",
    "    <p>Open your <b>Machine Learning Model Handbook</b> to Exercise 1. Then type the scientific question to be answered for this situation.</p>\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "*** \n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40af46bf-61eb-4cdd-8701-aa774ffce5af",
   "metadata": {},
   "source": [
    "## Part 2: Data Handling\n",
    "\n",
    "<center><a href=\"https://elearning.unidata.ucar.edu/dataeLearning/Cybertraining/analysis/media/RevisedFull_NOPROCESS_.png\" target=\"blank\"><img src=\"https://elearning.unidata.ucar.edu/dataeLearning/Cybertraining/analysis/media/RevisedFull_NOPROCESS_.png\"></a><br><i>Click to enlarge</i></center>\n",
    "<br><br>\n",
    "\n",
    "Recall that data handling is often the most time-consuming step of developing a machine learning model. Data handling comes in three parts:\n",
    "1. Locate data of interest\n",
    "2. Explore data\n",
    "3. Create a data splitting strategy\n",
    "\n",
    "Your team's data engineer has located the data and completed the pre-processing for you already. You will contnue with your own independent exploration of the data and then create a data splitting strategy. \n",
    "\n",
    "<br>\n",
    "\n",
    "### Part 2a: Locate Data of Interest\n",
    "\n",
    "You will be using other stations in the <a href=\"https://econet.climate.ncsu.edu/\" target=\"blank\">NC ECONet</a> for this project. Below is a document that your team's data engineer has prepared for you describing the nature of the dataset that will be used to create the machine learning model. <br><br>\n",
    "\n",
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "### Metadata Document for Western North Carolina Weather Station Data\n",
    "\n",
    "#### General Information\n",
    "\n",
    "Dataset Name: Western NC Weather Station Time-Series Data\n",
    "\n",
    "Description: This dataset contains tabular time series data collected from multiple surface weather stations in Western North Carolina. The data includes atmospheric and environmental variables recorded at hourly intervals.\n",
    "\n",
    "Date Range: January 1, 2015, to December 16, 2024\n",
    "\n",
    "Geographic Coverage: Western North Carolina \n",
    "\n",
    "Data Frequency: Hourly\n",
    "\n",
    "Last Updated: Jan 1, 2025\n",
    "\n",
    "#### Data Structure\n",
    "\n",
    "File Format: .parquet\n",
    "\n",
    "Number of Records: 69,760 per station per environmental variable (feature)\n",
    "\n",
    "Columns (Features) \n",
    "\n",
    "- observation_datetime: Date and time of observation in UTC\n",
    "\n",
    "Columns (features) per Station (XXXX):\n",
    "\n",
    "- XXXX_airtemp_degF (Â°F): Air temperature measured at 2 meters above ground level\n",
    "- XXXX_windspeed_mph (mph): Average wind speed during the hour at 10 meters above ground level\n",
    "- XXXX_winddgust_mph (mph): Peak wind gust during the hour at 10 meters above ground level\n",
    "- XXXX_rh_percent (%): Average Relative humidity\n",
    "- XXXX_precip_in (in): Total precipitation accumulated in the hour\n",
    "\n",
    "Stations:\n",
    "\n",
    "- BEAR (Bearwallow Mountain)\n",
    "- BURN (Burnsville Tower)\n",
    "- FRYI (Frying Pan Mountain)\n",
    "- JEFF (Mount Jefferson Tower)\n",
    "- **MITC (Mount Mitchell State Park) - target station**\n",
    "- NCAT (North Carolina A&T University Research Farm)\n",
    "- SALI (Piedmont Research Station)\n",
    "- SASS (Sassafrass Mountain)\n",
    "- UNCA (University of North Carolina - Asheville Weather Tower)\n",
    "- WINE (Wayah Bald Mountain)\n",
    "\n",
    "<a href=\"https://econet.climate.ncsu.edu/\" target=\"blank\">More station info</a>\n",
    "\n",
    "#### Data Quality\n",
    "\n",
    "Missing Data: Missing data (aside from MITC) was filled in using seasonal values and simple interpolation.\n",
    "\n",
    "Outlier Handling: No outlier handling was done. \n",
    "\n",
    "#### Data Provenance\n",
    "\n",
    "Source: North Carolina State Climate Office ECONet (<a href=\"https://journals.ametsoc.org/view/journals/atot/40/6/JTECH-D-22-0079.1.xml\" target=\"blank\">Citation</a>)\n",
    "\n",
    "</div>\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ce9319-3e5c-4632-a488-b777f93c9603",
   "metadata": {},
   "source": [
    "### Part 2b: Explore Data\n",
    "\n",
    "While your data engineer colleague prepared the data for your model and created the metadata document, you will still need to familiarize yourself with the data before you use it as input to a machine learning algorithm. In this step, you will take a closer look at the potential features for your model with a few plots. \n",
    "\n",
    "First, let's read the data into this workspace. The data resides on a remote THREDDS Data Server, which serves data to users without the need to manually download files to a local computer. When you execute the code cell below, you will load the Python library `pandas` that includes all the tools for reading the data from the THREDDS Data Server and opening it in this workspace. \n",
    "\n",
    "> **Instructions**\n",
    "> \n",
    "> Execute the  cell below.\n",
    "> \n",
    "> *This may take a moment to complete.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d6c37c-c245-4006-9e15-2c3674b17da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pandas Python library that can interpret the data file\n",
    "import pandas as pd\n",
    "\n",
    "# Location of the data on the THREDDS data server\n",
    "file_path = 'https://thredds.ucar.edu/thredds/fileServer/cybertraining/CyberTraining_NC_ECOnet_data.parquet'\n",
    "\n",
    "# Read data into this workspace\n",
    "df = pd.read_parquet(file_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4557a370-47ac-4762-ab41-b3dabb6e678c",
   "metadata": {},
   "source": [
    "The ***target features*** (the features that we are trying to predict with the machine learning model) are temperature, relative humidity, wind speed, wind gust, and precipitation at the Mt. Mitchell station. Data from the other nearby stations are possible ***input features*** to the model. \n",
    "\n",
    "#### Explore target features\n",
    "\n",
    "Let's now explore just the target features at Mt. Mitchell.  \n",
    "\n",
    "\n",
    "> **Instructions**\n",
    "> \n",
    "> Execute the two cells below.\n",
    "> \n",
    "> In the Mt. Mitchell plotting widget, select the environmental variable and plot type from the dropdowns, then select Plot to reveal the plot.\n",
    ">\n",
    "> Repeat for any and all variales you want to explore to better understand the data at Mt. Mitchell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb05b604",
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis_tech import display_mt_mitchell_weather_dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9581a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_mt_mitchell_weather_dashboard(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ba0556d7-3f62-486a-8940-85395948e0be",
   "metadata": {},
   "source": [
    "#### Explore input features\n",
    "\n",
    "Now we will explore the ***input features***. Below is a map of where the stations are located in relation to MITC. Western North Carolina is a part of the Appalachian Mountains in the eastern United States, so stations are located at a variety of elevations. To further explore the terrain in the area, click the image below to open an interactive 3D map.   \n",
    "\n",
    "<center><a href=\"https://ncar.maps.arcgis.com/apps/instant/3dviewer/index.html?appid=50f8315bfb4742ce9468e25eaf53c12e\" target=\"blank\"><img src=\"https://elearning.unidata.ucar.edu/dataeLearning/Cybertraining/analysis/media/stationmap_pro.png\" width=\"500 px\"></a><br>\n",
    "<i>Click to open interactive map</i></center>\n",
    "\n",
    "> **Instructions**\n",
    "> \n",
    "> Execute the two cells below.\n",
    ">\n",
    "> In the Input Stations plotting widget, select the station, environmental variable, and plot type from the dropdowns. Then select Plot to reveal the plot.\n",
    ">\n",
    "> Repeat for any and all variables you want to explore to better understand the data at each station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68121f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis_tech import display_input_stations_dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81b0e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_input_stations_dashboard(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c12f3e",
   "metadata": {},
   "source": [
    "#### Compare stations\n",
    "We can also plot direct comparisons of stations in our dataset by plotting data at each station in a grid of plots. In these comparison grids, the scatter plots display the observations at each station at a given time. For example, the temperature at MITC on the x-axis and the temperature at SASS on the y-axis. Stations with variables that are well-correlated will show points that are generally clustered along a line with very little spread, whereas stations with variables that are not well-correlated show considerable spread. \n",
    "\n",
    "<center><a href=\"https://elearning.unidata.ucar.edu/dataeLearning/Cybertraining/analysis/media/wellcorrelated.png\" target=\"blank\"><img src=\"https://elearning.unidata.ucar.edu/dataeLearning/Cybertraining/analysis/media/wellcorrelated.png\" width=\"200 px\"></a> <a href=\"https://elearning.unidata.ucar.edu/dataeLearning/Cybertraining/analysis/media/notwellcorrelated.png\" target=\"blank\"><img src=\"https://elearning.unidata.ucar.edu/dataeLearning/Cybertraining/analysis/media/notwellcorrelated.png\" width=\"200 px\"></a><br><i>Click to enlarge</i></center>\n",
    "\n",
    "The comparison plot grid displays histograms where the x- and y-axes are the same station. These are the same histograms that you plotted previously, displaying the distribution of all values at that station. \n",
    "\n",
    "> **Instructions**\n",
    "> \n",
    "> Execute the two cells below.\n",
    ">\n",
    "> In the Comparison Plot plotting widget, select an environmental variable from the dropdown, then select Plot to reveal the plot.\n",
    "> \n",
    "> Repeat for any and all variables you want to explore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c922a5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis_tech import display_correlation_plot_dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63663049",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_correlation_plot_dashboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49eb31c-c0cf-477d-a771-282d49442189",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "<p class=\"admonition-title\" style=\"font-weight:bold\">Exercise 2b</p>\n",
    "    <p>Open your <b>Machine Learning Model Handbook</b> to Exercise 2b. Then describe your exploratory data analysis of any target and input features of note. Include the following:\n",
    "    <ul>\n",
    "        <li>Do variables follow diurnal or annual patterns generally as expected?</li>\n",
    "        <li>Do the variables have the expected ranges of values? Do any variables appear to include major outliers?</li>\n",
    "        <li>Which stations appear to be most correlated to the variables at Mt Mitchell? Why?</li>\n",
    "        <li>Include any <i>important</i> plots to illustrate your conclusions. Limit yourself to 5 plots. <br><i>To copy a plot image, hold shift, right click on the image, then select Copy.</i></li>\n",
    "    </ul>\n",
    "    </p>\n",
    "</div>\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2179f158-8f6b-45f3-ab00-aa889b092160",
   "metadata": {},
   "source": [
    "### Part 2c: Create a data splitting strategy\n",
    "\n",
    "Next we create a data splitting strategy. Data splitting refers to the process of dividing data into three groups: training, validation, and testing. Each of these groups represent a part of the iterative process for machine learning model development. \n",
    "\n",
    "- Training data is the largest subset, usually around 60-80% of the total data, and is used to initially train the model. \n",
    "- Validation data is roughly 10-20% of the total data, and is used to validate the effectiveness of the training process. \n",
    "- Testing data is also roughly 10-20% of the total data, and is used to test the final refined model before using it on new, unseen data.\n",
    "\n",
    "Each group should be separate to ensure no single group will bias the model. In this model, the data will be randomly split into these groups, but you decide the proportions of data for each group. Input your percentages in the blanks below, ensuring all percentages equal 100%.\n",
    "\n",
    "> **Instructions**\n",
    "> \n",
    "> Execute the two cells below.\n",
    ">\n",
    "> In the Dataset Split Percentages widget, select the proportions of the total dataset you wish to use in each group by typing in each box. Use values 0-100, ensuring that the sum of all three boxes equals 100.\n",
    ">\n",
    "> Select Submit after making your selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386cc8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis_tech import create_percentage_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0d113b",
   "metadata": {},
   "outputs": [],
   "source": [
    "widget, get_values = create_percentage_widget()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7aa6420-48c4-44d5-a6a2-3a9fa6c32db8",
   "metadata": {},
   "source": [
    "> **Instructions**\n",
    "> \n",
    "> Execute the three cells below to execute the functions to split the data according to the percentages you submitted above.\n",
    ">\n",
    "> *Note: The \"true test\" group is the subset of times where MITC was offline, Sept 27, 2024 and onward.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d1273d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is used to grab the values from the widget above (no need to change)\n",
    "decimals = get_values()\n",
    "training = decimals['training']\n",
    "validation = decimals['validation']\n",
    "testing = decimals['testing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c11ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis_tech import split_data_temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4547defa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the function\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, X_true_test, y_true_test = split_data_temporal(df,\n",
    "                                                                                               train_pct=training,\n",
    "                                                                                               val_pct=validation,\n",
    "                                                                                               test_pct=testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9510216-b184-4de8-96a6-965f2a5042f1",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "<p class=\"admonition-title\" style=\"font-weight:bold\">Exercise 2c</p>\n",
    "    <ul>\n",
    "        <li><b>In your Machine Learning Model Handbook Exercise 2c,</b> input your data splitting strategy. </li>\n",
    "    </ul>\n",
    "</div>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055833d1-35ab-4553-935a-766209357f72",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b94e17c2-14c8-400e-9882-1016a33d888c",
   "metadata": {},
   "source": [
    "## Part 3: Model Development\n",
    "Next begins the iterative process of creating, evaluating, and refining your machine learning model. You will start with an initial model, and keep track of your subsequent trials in your Machine Learning Model Handbook. \n",
    "<center><a href=\"https://elearning.unidata.ucar.edu/dataeLearning/Cybertraining/analysis/media/RevisedFull_NOPROCESS_.png\" target=\"blank\"><img src=\"https://elearning.unidata.ucar.edu/dataeLearning/Cybertraining/analysis/media/RevisedFull_NOPROCESS_.png\"></a><br><i>Click to enlarge</i></center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc10b05e-e441-4af5-b7b5-e925294cf261",
   "metadata": {},
   "source": [
    "### Part 3a: Choose Algorithm\n",
    "First, you will choose an algorithm to train. You have two options: the *MultiXGBRegressor* and the *MultiLinearRegressor*. Both have pros and cons for this task. Choose one for your initial model, but you may choose to test the other algorithm in subsequent trials. \n",
    "\n",
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">About the Algorithms</p>\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">MultiXGBRegressor (XGBoost)</p>\n",
    "    <ul>\n",
    "        <li>Handles a Wide Range of Data Distributions: XGBoost is capable of modeling both linear and non-linear relationships, making it suitable for data with complex, varied distributions.</li>\n",
    "        <li>Prone to Overfitting: XGBoost can easily overfit to training data, especially when the dataset is small or noisy. This may lead to poor generalizations when making predictions on new data. </li>\n",
    "    </ul>\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">MultiLinearRegressor</p>\n",
    "    <ul>\n",
    "        <li>Simple and Interpretable: As a linear model, it is easy to understand and interpret within the context of the physical world, making it a great choice for finding clear relationships between features and predictions.</li>\n",
    "        <li>Struggles with Non-Uniform Data Distributions: For datasets with non-linear patterns or skewed distributions, multiple linear regression may fail to capture the underlying patterns, leading to biased or inaccurate predictions.</li>\n",
    "</div>\n",
    "\n",
    "> **Instructions**\n",
    "> \n",
    "> Execute the two cells below.\n",
    ">\n",
    "> After executing `algorithm_selection()`, select the corresponding button to select your desired algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14e8307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports needed to run the machine learning workflow\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "import time \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from analysis_tech import algorithm_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095e21a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_algo = algorithm_selection()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "18b99dcf-1fa1-4e03-b826-492e5b71fb91",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Part 3b: Choose input features\n",
    "\n",
    "Given your data exploration, you must now choose the stations to use as input features to the algorithm you just selected. You may choose as many input stations as you'd like, however, recall that more stations does not always create a better model. Think strategically based on the evidence. \n",
    "\n",
    "<center><a href=\"https://ncar.maps.arcgis.com/apps/instant/3dviewer/index.html?appid=50f8315bfb4742ce9468e25eaf53c12e\" target=\"blank\"><img src=\"https://elearning.unidata.ucar.edu/dataeLearning/Cybertraining/analysis/media/stationmap_pro.png\" width=\"500 px\"></a><br>\n",
    "<i>Click to open interactive map</i></center><br>\n",
    "\n",
    "> **Instructions**\n",
    "> \n",
    "> Execute the two cells below.\n",
    ">\n",
    "> After executing `create_station_selector()`, select the stations you would like to use to train your model. You may select as many or as few as you consider necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9edb193",
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis_tech import create_station_selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de3be7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_selector = create_station_selector()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7c1f45-54ea-4600-8563-f9d2e429bd6e",
   "metadata": {},
   "source": [
    "> **Instructions**\n",
    "> \n",
    "> Execute the cell below to commit your station selection. The output will also be used in describing subsequent evaluation metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0c9b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get selected stations at any time:\n",
    "def get_selected_stations(selector):\n",
    "    return [station for station, checkbox in selector.items() if checkbox.value]\n",
    "\n",
    "selected = get_selected_stations(station_selector)\n",
    "selected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68eeb52",
   "metadata": {},
   "source": [
    "This next block of code takes the full dataset and removes (filters) any stations that were not selected above. We do this for all groups (training, validation, and testing). \n",
    "\n",
    "The \"true test\" group is the subset of times where MITC was offline, Sept 27, 2024 and onward.\n",
    "\n",
    "<br>\n",
    "\n",
    "> **Instructions**\n",
    "> \n",
    "> Execute the two cells below. In the printout display, you will see the number of features (columns) in the original dataset, and the number of features in the filtered dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de1e99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis_tech import filter_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b094c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_filtered     = filter_dataframe(X_train,     selected)\n",
    "X_val_filtered       = filter_dataframe(X_val,       selected)\n",
    "X_test_filtered      = filter_dataframe(X_test,      selected)\n",
    "X_true_test_filtered = filter_dataframe(X_true_test, selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fbcd3e-bd91-4b20-9bb4-d354926e5472",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Part 3c: Train the Algorithm\n",
    "\n",
    "The training process is what transforms the machine learning algorithm into a supervised machine learning model. The cells below start the training process with all the decisions you previously made. \n",
    "\n",
    "> **Instructions**\n",
    "> \n",
    "> Execute the two cells below.\n",
    ">\n",
    "> After executing `train_button()`, select the Train Algorithm button to initiate the training process. A progress printout will display below the button while the process runs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a388a0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis_tech import train_button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9e11f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_choice = selected_algo()\n",
    "trained_model = train_button(model_choice, X_train_filtered, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61c36ec-46d9-4d79-ade1-55bf639cabae",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Part 3d: Validate the Model\n",
    "\n",
    "The validation step uses validation data to evaluate how well the training process performed. By using a separate dataset to evaluate performance, we get a better sense of how well the model can generalize to new inputs. We focus on two main evaluation metrics: Root Mean Square Error (RMSE) and RÂ². \n",
    "\n",
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">About the Evaluation Metrics</p>\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">Root Mean Square Error (RMSE)</p>\n",
    "    <ul>\n",
    "        <li>A measure of how large a typical prediction error is</li>\n",
    "        <li>Reports the typical magnitude of error in the original units (degrees, %, mph, etc)</li>\n",
    "        <li>The closer to 0, the better the model accuracy</li>\n",
    "        <li>Better reflects the accuracy of predictions in real-world situations</li>\n",
    "        <li>Dependent on the range of values (scale) of the dataset, making comparisons among variables more difficult</li>\n",
    "    </ul>\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">RÂ²</p>\n",
    "    <ul>\n",
    "        <li>A measure of how well the model explains the variation in the dataset</li>\n",
    "        <li>Uses a standardized scale (0-1) for comparing models across different trials</li>\n",
    "            <ul>\n",
    "                <li>In some cases, RÂ² may be negative. This means that the model made a prediction worse than the dataset average (or climatology prediction).</li>\n",
    "            </ul>\n",
    "        <li>The closer to 1, the better the model accuracy</li>\n",
    "        <li>Assumes that the input data have a linear relationship</li>\n",
    "        <li>Only measures correlation among input data, cannot distinguish good and bad predictions in the real world</li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "\n",
    "> **Instructions**\n",
    "> \n",
    "> Execute the two cells below.\n",
    ">\n",
    "> After executing `model_eval_MITC()`, your model's validation metrics will appear below as a printout. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66842084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Python libraries that calculate the evaluation metrics\n",
    "import numpy as np\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score\n",
    "\n",
    "from analysis_tech import model_eval_MITC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0ff68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eval_MITC(trained_model(), X_test_filtered, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f3e964-4f0a-44d5-baa1-65b9c9a4d169",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Part 3e: Evaluate and Refine the Model\n",
    "\n",
    "Examine the results of the model validation. What do each mean? Could they be improved? Review the descriptions of the evaluation metrics, then complete the next exercise. \n",
    "\n",
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "<p class=\"admonition-title\" style=\"font-weight:bold\">Exercise 3e</p>\n",
    "    <p>Open your <b>Machine Learning Model Handbook</b> to Exercise 3e. </p>\n",
    "    <p>Paste your validation evaluation metrics in the designated box. </p>\n",
    "    <p>Then describe the results of your initial model validation. Include the following:</p>\n",
    "    <ul>\n",
    "        <li>Which variables have favorable evaluation metrics? Which variables donât perform as well?</li>\n",
    "        <li>How do you interpret these statistics in the context of the physical world?</li>\n",
    "        <li>What changes will you make to try to improve these statistics in the next iteration?</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4c6653-d035-4415-b953-962328ce1e73",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Part 3f: Iterative Refinement Trials\n",
    "\n",
    "Your first trial is complete! Now you'll create new trials to improve the evaluation metrics from the validation phase. You may complete as many trials as you like until you are satisfied with the evaluation metrics, or they no longer improve with new trials. \n",
    "\n",
    "> **Instructions**\n",
    "> \n",
    "> Execute the code cells below, selecting your desired model configurations after executing each cell.\n",
    "> \n",
    "> After each new trial, you will copy the validation metrics in your handbook document. See **Exercise 3f**.\n",
    ">\n",
    "> You may complete as many trials in this section (3f) as you like until you are satisfied with the evaluation metrics, or they no longer improve with new trials. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9c160b-404d-4447-acdd-eb4d93027bfd",
   "metadata": {},
   "source": [
    "#### New trial: Choose algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dbcb1c-5319-40f4-9b9c-3d6fe3bf2e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_algo = algorithm_selection()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423ab52a-3957-4660-a178-e5824a58c636",
   "metadata": {},
   "source": [
    "#### New trial: Choose input features\n",
    "\n",
    "<center><a href=\"https://ncar.maps.arcgis.com/apps/instant/3dviewer/index.html?appid=50f8315bfb4742ce9468e25eaf53c12e\" target=\"blank\"><img src=\"https://elearning.unidata.ucar.edu/dataeLearning/Cybertraining/analysis/media/stationmap_pro.png\" width=\"500 px\"></a><br>\n",
    "<i>Click to open interactive map</i></center><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b12ae6-e2ab-4e2f-b0ae-736b84e2b967",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_selector = create_station_selector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6ca79a-1d43-457c-9997-9eef3d0bc1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute this cell after selecting stations\n",
    "selected = get_selected_stations(station_selector)\n",
    "X_train_filtered     = filter_dataframe(X_train,     selected)\n",
    "X_val_filtered       = filter_dataframe(X_val,       selected)\n",
    "X_test_filtered      = filter_dataframe(X_test,      selected)\n",
    "X_true_test_filtered = filter_dataframe(X_true_test, selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98ed0d1-3526-45b3-8649-50aada35023d",
   "metadata": {},
   "source": [
    "#### New trial: Train algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7ab4b7-cdb3-4a8b-bbab-f1b5776b1639",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_choice = selected_algo()\n",
    "trained_model = train_button(model_choice, X_train_filtered, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ded4e98-f356-4000-b209-e7b98a075d52",
   "metadata": {},
   "source": [
    "#### New trial: Validate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fe5c25-b1f9-437e-bf6f-dc97ed8e1d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eval_MITC(trained_model(), X_test_filtered, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ec7a1c-93ad-46e3-80cb-a7aa924aba84",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "<p class=\"admonition-title\" style=\"font-weight:bold\">Exercise 3f</p>\n",
    "    <ul>\n",
    "        <li><b>In your Machine Learning Model Handbook Exercise 3f,</b> paste the full output of each of your validation trials, one per box. </li>\n",
    "        <li>You may complete as many trials as you like until you are satisfied with the evaluation metrics, or they no longer improve with new trials. When complete, move on to the next part below. </li>\n",
    "    </ul>\n",
    "</div>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37323e1-2a75-4f9b-9071-a3e79cd78dd5",
   "metadata": {},
   "source": [
    "### Part 3g: Test Model\n",
    "\n",
    "<div class=\"alert alert-warning\" role=\"alert\">\n",
    "<p class=\"admonition-title\" style=\"font-weight:bold\">Important</p>\n",
    "    For testing, your model needs to be in a state with your desired algorithm and input feature stations. If you haven't already, go back and run through the cells in Part 3f with your final choices one last time. This ensures that your final testing process will be executed with your desired choices. \n",
    "</div>\n",
    "<br>\n",
    "At this point, you have a trained model with validation metrics you are satisfied with. Next, it's time to test the model on brand new data: the testing dataset. The testing process mimics how the model would be used in a real-world process in a final, unbiased way. \n",
    "<br><br>\n",
    "Testing looks very similar to validation. The model makes predictions based on the input features in the testing dataset, we calculate RMSE and RÂ² as the testing metrics. \n",
    "\n",
    "> **Instructions**\n",
    "> \n",
    "> Execute the cell below.\n",
    ">\n",
    "> After executing `model_eval_MITC()`, your model's testing metrics will appear below as a printout. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c4350a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eval_MITC(trained_model(), X_val_filtered, y_val, eval_type='Testing')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e20b35-3933-457a-b454-925143761974",
   "metadata": {},
   "source": [
    "### Part 3h: Evaluate and Justify\n",
    "\n",
    "With your model trained, validated, and tested, you can now plot the predicted model output alongside the real data before the Mt. Mitchell station went offline. You may use this information to help you address your final model justification. \n",
    "\n",
    "> **Instructions**\n",
    "> \n",
    "> Execute the three cells below.\n",
    ">\n",
    "> The plot displays the historical and model-predicted data at Mt. Mitchell in the calendar year 2024. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378da27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "y_pred = trained_model().predict(X_true_test_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be56b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis_tech import plot_weather_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a433778",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plot_weather_comparison(\n",
    "   df=df,\n",
    "   y_pred=y_pred, \n",
    "   transition_date=pd.Timestamp('2024-09-28')\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d4f576-7b33-4eb8-a958-0470baf0565b",
   "metadata": {},
   "source": [
    "#### Your final decision\n",
    "\n",
    "Given all your evaluation, it's time to make a final decision on whether you believe this model provides sufficient skill for the needs of the situation. Go back and review your problem statement. Does this model deliver the results needed?\n",
    "\n",
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "<p class=\"admonition-title\" style=\"font-weight:bold\">Exercise 3h</p>\n",
    "    <p>Open your <b>Machine Learning Model Handbook</b> to Exercise 3h.</p>\n",
    "    <p>Paste your testing evaluation metrics in the designated box. </p>\n",
    "    <p>Then  make a final decision on whether this model delivers on the results needed with supporting justification. Include the following:\n",
    "    <ul>\n",
    "        <li>Which environmental variables had the best evaluation metrics? List some physical scientific reasons why this may be the case.</li>\n",
    "        <li>Is this model ready for use in the real world? Why or Why not?</li>\n",
    "        <li>What other possible changes could further improve this model?</li>\n",
    "    </ul>\n",
    "    </p>\n",
    "</div>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9537e8b9-9d60-4e1b-b40e-ee1126c0bdc9",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "Scientific research rarely yields a simple and straightforward right answer. Instead, scientists analyze evidence, compare it to known physical processes, and make informed recommendations based on data and statistics. As you learned in *Machine Learning Foundations in the Earth System Sciences*, machine learning is not an exact science, rather, it generates approximations from large datasets. This makes evaluating model quality complex. What one scientist considers a high-performing model may be insufficient to another. What matters most is your ability to justify your results within the context of physical science and the real-world stakes. As you continue your studies, remember that these models are not just numbers. They are representations of the physical world."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98948be-d20b-432d-8205-ea9b7c0b3586",
   "metadata": {},
   "source": [
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2149feb2-3ac0-4dd0-9877-53baff421aeb",
   "metadata": {},
   "source": [
    "#### Acknowledgements\n",
    "\n",
    "This work was supported by NSF Unidata under award #2319979 from the US National Science Foundation. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation. \n",
    "\n",
    "We thank the <a href=\"https://climate.ncsu.edu/\" target=\"blank\">North Carolina State Climate Office</a> for contributing <a href=\"https://doi.org/10.1175/JTECH-D-22-0079.1\" target=\"blank\">NC ECONet data</a> and media to this project. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
